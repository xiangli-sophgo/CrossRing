# 大模型部署详解

> 本文档旨在帮助完全没有大模型背景的读者理解什么是大模型部署，为什么需要部署，以及如何选择最优的部署方案。

---

## 目录

1. [什么是大模型？](#一什么是大模型)
2. [什么是部署？为什么需要部署？](#二什么是部署为什么需要部署)
3. [核心挑战：模型太大放不下](#三核心挑战模型太大放不下)
4. [并行策略详解](#四并行策略详解)
5. [通信原语详解](#五通信原语详解)
6. [部署方案设计与权衡](#六部署方案设计与权衡)
7. [实际案例分析](#七实际案例分析)
8. [总结与最佳实践](#八总结与最佳实践)

---

## 一、什么是大模型？

### 1.1 从神经网络到大模型

**神经网络**是一种模仿人脑工作方式的计算模型。它由大量的"神经元"（数学函数）组成，这些神经元之间通过"权重"（数值参数）相连。

```
输入 → [神经元层1] → [神经元层2] → ... → [神经元层N] → 输出
           ↑              ↑                    ↑
        权重矩阵W1      权重矩阵W2           权重矩阵WN
```

**大模型 = 参数量巨大的神经网络**

| 模型      | 参数量           | 类比             |
| --------- | ---------------- | ---------------- |
| ResNet-50 | 2500万           | 一本书的字数     |
| BERT-Base | 1.1亿            | 一个小型图书馆   |
| GPT-3     | 1750亿           | 全世界所有图书馆 |
| GPT-4     | ~1.8万亿（估计） | 难以想象         |

### 1.2 参数是什么？

每个参数就是一个**数字**。模型通过学习调整这些数字，使其能够完成特定任务（如回答问题、生成图片）。

```
例如一个简单的线性层：
y = W × x + b

其中：
- W 是权重矩阵（比如 4096 × 4096 = 1677万个参数）
- b 是偏置向量（4096个参数）
- x 是输入
- y 是输出
```

### 1.3 参数需要多少存储空间？

参数存储取决于**数据类型**：

| 数据类型  | 每个参数占用 | 说明             |
| --------- | ------------ | ---------------- |
| FP32      | 4 字节       | 全精度，训练常用 |
| FP16/BF16 | 2 字节       | 半精度，推理常用 |
| INT8      | 1 字节       | 量化后           |
| INT4      | 0.5 字节     | 极限量化         |

**举例：LLaMA-70B模型**

- 参数量：700亿 = 70 × 10^9
- FP16存储：70 × 10^9 × 2 字节 = 140 GB

---

## 二、什么是部署？为什么需要部署？

### 2.1 训练 vs 部署

| 阶段           | 目标             | 特点                                  |
| -------------- | ---------------- | ------------------------------------- |
| **训练** | 让模型"学会"技能 | 需要海量数据、海量算力、可能耗时数月  |
| **部署** | 让模型"提供服务" | 需要快速响应、高吞吐量、7×24小时运行 |

```
训练阶段：
┌─────────────┐     ┌─────────────┐     ┌─────────────┐
│  海量数据   │ ──→ │  模型学习   │ ──→ │ 训练好的模型 │
│ (TB级别)   │     │ (数周~数月) │     │  (权重文件)  │
└─────────────┘     └─────────────┘     └─────────────┘

部署阶段：
┌─────────────┐     ┌─────────────┐     ┌─────────────┐
│  用户请求   │ ──→ │  模型推理   │ ──→ │   返回结果   │
│ "北京天气" │     │ (毫秒级别) │     │ "北京今天..." │
└─────────────┘     └─────────────┘     └─────────────┘
```

### 2.2 部署的定义

**部署**是将训练好的模型放到硬件设备上，使其能够：

1. 接收用户请求
2. 执行模型计算（推理）
3. 返回计算结果

### 2.3 为什么部署是个难题？

#### 问题1：模型太大，单张GPU放不下

```
┌────────────────────────────────────────┐
│              LLaMA-70B                 │
│           需要 140GB 显存              │
└────────────────────────────────────────┘
                    ↓
              放不进去！
                    ↓
┌────────────────────────────────────────┐
│            NVIDIA H100                 │
│           只有 80GB 显存               │
└────────────────────────────────────────┘
```

#### 问题2：计算量太大，响应太慢

```
GPT-4 回答一个问题：
- 需要执行约 1.8万亿次乘加运算（每生成一个token）
- 生成100个token需要 180万亿次运算
- 如果用单张GPU，可能需要几分钟

用户期望：秒级响应
```

#### 问题3：用户量太大，单机处理不过来

```
假设：
- 每秒1000个用户请求
- 每个请求需要100ms
- 单GPU每秒只能处理10个请求

需要：1000 / 10 = 100张GPU并行处理
```

### 2.4 部署的目标

| 目标             | 含义         | 衡量指标                |
| ---------------- | ------------ | ----------------------- |
| **低延迟** | 快速响应用户 | 首token延迟、端到端延迟 |
| **高吞吐** | 处理更多请求 | tokens/秒、requests/秒  |
| **高效率** | 充分利用硬件 | GPU利用率、显存利用率   |
| **低成本** | 节省资源开支 | 每千tokens成本          |

---

## 三、核心挑战：模型太大放不下

### 3.1 显存都用来存什么？

以推理为例，GPU显存需要存储：

```
┌─────────────────────────────────────────────────────┐
│                    GPU显存分配                       │
├─────────────────────────────────────────────────────┤
│  ┌─────────────────────────────────────────────┐    │
│  │            模型权重 (Model Weights)          │    │
│  │         LLaMA-70B: 140GB (FP16)             │    │
│  └─────────────────────────────────────────────┘    │
│  ┌─────────────────────────────────────────────┐    │
│  │            KV Cache (缓存)                   │    │
│  │    存储历史token的Key和Value，避免重复计算     │    │
│  │    大小随序列长度线性增长                      │    │
│  └─────────────────────────────────────────────┘    │
│  ┌─────────────────────────────────────────────┐    │
│  │            激活值 (Activations)              │    │
│  │         前向传播的中间计算结果                 │    │
│  └─────────────────────────────────────────────┘    │
└─────────────────────────────────────────────────────┘
```

### 3.2 显存计算示例

**场景：部署 LLaMA-70B，batch_size=8，序列长度=2048**

```
1. 模型权重：
   70B × 2字节(FP16) = 140 GB

2. KV Cache：
   = 2 × batch × seq_len × num_layers × num_kv_heads × head_dim × 2字节
   = 2 × 8 × 2048 × 80 × 8 × 128 × 2
   = 52.4 GB

3. 激活值（峰值）：
   ≈ batch × seq_len × hidden_size × 若干层
   ≈ 8 × 2048 × 8192 × 4层 × 2字节
   ≈ 1 GB

总计：140 + 52.4 + 1 ≈ 193.4 GB
```

**结论：单张H100（80GB）远远不够！**

### 3.3 解决方案：切分模型

既然一张卡放不下，就把模型**切开**，分到多张卡上：

```
                    LLaMA-70B (140GB)
                          │
        ┌─────────────────┼─────────────────┐
        ↓                 ↓                 ↓
   ┌─────────┐       ┌─────────┐       ┌─────────┐
   │  GPU 0  │       │  GPU 1  │       │  GPU 2  │
   │  47GB   │       │  47GB   │       │  46GB   │
   └─────────┘       └─────────┘       └─────────┘
```

**但问题来了：**

- 怎么切？横着切还是竖着切？
- 切开后，不同GPU之间如何协作？
- 通信开销有多大？

这就是**并行策略**要解决的问题。

---

## 四、并行策略详解

并行策略定义了如何将模型、数据、计算分布到多个设备上。主要有5种策略：

| 策略       | 缩写 | 核心思想                         |
| ---------- | ---- | -------------------------------- |
| 数据并行   | DP   | 每张卡都有完整模型，处理不同数据 |
| 张量并行   | TP   | 把单层的权重矩阵切到多卡         |
| 流水线并行 | PP   | 把不同层分到不同卡               |
| 专家并行   | EP   | MoE模型专用，不同专家放不同卡    |
| 序列并行   | SP   | 把长序列切分到多卡               |

### 4.1 数据并行 (Data Parallelism, DP)

#### 核心思想

每张GPU都有**完整的模型副本**，但处理**不同的数据**。

```
用户请求队列：[请求1, 请求2, 请求3, 请求4, ...]
                     │
     ┌───────────────┼───────────────┐
     ↓               ↓               ↓
┌─────────┐    ┌─────────┐    ┌─────────┐
│  GPU 0  │    │  GPU 1  │    │  GPU 2  │
│ 完整模型 │    │ 完整模型 │    │ 完整模型 │
│ 处理请求1│    │ 处理请求2│    │ 处理请求3│
└─────────┘    └─────────┘    └─────────┘
     │               │               │
     └───────────────┼───────────────┘
                     ↓
              [结果1, 结果2, 结果3]
```

#### 优点

- 实现简单
- 线性扩展吞吐量（3张卡 = 3倍吞吐）
- 无需复杂的跨卡通信

#### 缺点

- **前提：单卡能放下整个模型**
- 对于70B+的大模型，单卡放不下，DP无法单独使用

#### 适用场景

- 小模型（7B以下）的大规模部署
- 与其他并行策略组合使用

---

### 4.2 张量并行 (Tensor Parallelism, TP)

#### 核心思想

将单层的**权重矩阵**切分到多张GPU上，每张GPU只存储和计算一部分。

#### 以线性层为例

原始计算：`Y = X × W`，其中 W 是 [4096 × 4096] 的矩阵

```
TP=1（不切分）：
┌──────────────────────────────────────────┐
│                   GPU 0                   │
│  X [batch, 4096] × W [4096, 4096]        │
│  = Y [batch, 4096]                       │
└──────────────────────────────────────────┘

TP=2（切成2份）：
┌──────────────────────┐  ┌──────────────────────┐
│        GPU 0         │  │        GPU 1         │
│ X × W0 [4096, 2048]  │  │ X × W1 [4096, 2048]  │
│ = Y0 [batch, 2048]   │  │ = Y1 [batch, 2048]   │
└──────────────────────┘  └──────────────────────┘
           │                        │
           └───────── 拼接 ─────────┘
                      ↓
              Y [batch, 4096]
```

#### Transformer中的TP切分

Transformer的每一层包含：

1. **Attention模块**：QKV投影 + 输出投影
2. **FFN模块**：两个线性层

```
                    ┌─────────────────────────────┐
                    │        Transformer层         │
                    ├─────────────────────────────┤
                    │     Multi-Head Attention     │
输入 X ──→          │  ┌───┐ ┌───┐ ┌───┐ ┌───┐   │
                    │  │Q  │ │K  │ │V  │ │Out│   │
                    │  └───┘ └───┘ └───┘ └───┘   │
                    ├─────────────────────────────┤
                    │      Feed-Forward (FFN)      │
                    │  ┌────────┐   ┌────────┐    │
                    │  │ Linear1│ → │ Linear2│    │
                    │  └────────┘   └────────┘    │
                    └─────────────────────────────┘
                                  │
                                  ↓ 输出

TP=4时的切分方式：
┌────────────────────────────────────────────────────────┐
│                         一层 Transformer               │
├────────────┬────────────┬────────────┬────────────────┤
│   GPU 0    │   GPU 1    │   GPU 2    │     GPU 3      │
├────────────┼────────────┼────────────┼────────────────┤
│ Head 0-7   │ Head 8-15  │ Head 16-23 │   Head 24-31   │ ← Attention
│ FFN列0-1k  │ FFN列1k-2k │ FFN列2k-3k │  FFN列3k-4k   │ ← FFN
└────────────┴────────────┴────────────┴────────────────┘
                            │
                     需要AllReduce同步
```

#### TP的通信开销

**关键问题：每一层都需要通信！**

```
Attention计算流程：
   X ──→ [Q投影] ──→ [Attention计算] ──→ [Out投影] ──→ AllReduce ──→ 输出
         ↓                                  ↑
   X ──→ [K投影] ─────────────────────────┘
         ↓
   X ──→ [V投影] ─────────────────────────┘

FFN计算流程：
   输入 ──→ [Linear1] ──→ [激活函数] ──→ [Linear2] ──→ AllReduce ──→ 输出
```

**每层需要2次AllReduce**：

1. Attention输出后
2. FFN输出后

#### 优点

- 可以处理单卡放不下的大模型
- 减少每卡显存占用（显存 ÷ TP）
- 适合显存受限场景

#### 缺点

- **通信开销大**：每层都要AllReduce
- **对带宽要求高**：需要NVLink/NVSwitch级别的高速互联
- **延迟增加**：通信会阻塞计算

#### TP的显存和通信公式

```
每卡显存 = 模型参数 / TP + KV Cache + 激活值

每层通信量 = 2 × (TP-1)/TP × batch × seq × hidden × 2字节
总通信量 = 每层通信量 × 层数 × 2（Attention + FFN）
```

---

### 4.3 流水线并行 (Pipeline Parallelism, PP)

#### 核心思想

将模型的**不同层**分到不同GPU上，形成"流水线"。

```
假设模型有32层，PP=4：

┌──────────┐   ┌──────────┐   ┌──────────┐   ┌──────────┐
│  GPU 0   │ → │  GPU 1   │ → │  GPU 2   │ → │  GPU 3   │
│ Layer 0-7│   │Layer 8-15│   │Layer16-23│   │Layer24-31│
└──────────┘   └──────────┘   └──────────┘   └──────────┘
     ↓              ↓              ↓              ↓
   Stage 0       Stage 1       Stage 2       Stage 3
```

#### 流水线执行过程

**朴素方式（非流水线）**：

```
时间 →
GPU 0: [计算]─────────────────────────────────────────────────
GPU 1:       [等待]────────[计算]────────────────────────────
GPU 2:                            [等待]────[计算]───────────
GPU 3:                                             [等待]──[计算]

问题：大量时间在"等待"，GPU利用率极低！
```

**微批次流水线（Micro-batch Pipeline）**：

将一个大batch切成多个小的micro-batch，让流水线"流动"起来：

```
时间 →
GPU 0: [μ1][μ2][μ3][μ4][μ5][μ6]────────────────────────────
GPU 1:     [μ1][μ2][μ3][μ4][μ5][μ6]────────────────────────
GPU 2:         [μ1][μ2][μ3][μ4][μ5][μ6]────────────────────
GPU 3:             [μ1][μ2][μ3][μ4][μ5][μ6]────────────────

μ1~μ6 = 6个micro-batch
流水线更加饱满，但开头和结尾仍有"气泡"
```

#### 流水线气泡 (Pipeline Bubble)

```
时间 →
       ┌─────────────────────────────────────────────────────┐
GPU 0: │[μ1][μ2][μ3][μ4]                                    │
GPU 1: │气泡[μ1][μ2][μ3][μ4]                                │
GPU 2: │气泡气泡[μ1][μ2][μ3][μ4]                            │
GPU 3: │气泡气泡气泡[μ1][μ2][μ3][μ4]气泡气泡气泡            │
       └─────────────────────────────────────────────────────┘
             开头气泡              结尾气泡

气泡比 = (PP - 1) / (micro_batches + PP - 1)

例如：PP=4, micro_batches=4
气泡比 = 3 / (4 + 3) = 42.8%  ← 接近一半时间在空转！

例如：PP=4, micro_batches=16
气泡比 = 3 / (16 + 3) = 15.8%  ← 好多了
```

#### PP的通信特点

**只在Stage边界通信（点对点P2P），不需要AllReduce**：

```
GPU 0 ──→ GPU 1：传递Stage 0的输出（激活值）
GPU 1 ──→ GPU 2：传递Stage 1的输出
GPU 2 ──→ GPU 3：传递Stage 2的输出
```

通信量 = `batch × seq × hidden × 2字节`（每个Stage边界）

#### 优点

- 显存均匀分布（每卡只存部分层）
- 通信量相对较小（只在边界通信）
- 适合跨节点部署（可以用较慢的网络）

#### 缺点

- 流水线气泡导致效率损失
- micro-batch太小会影响计算效率
- 需要精心设计micro-batch数量

---

### 4.4 专家并行 (Expert Parallelism, EP)

#### 什么是MoE？

**MoE (Mixture of Experts)** 是一种稀疏激活的模型架构：

```
传统Dense模型（所有参数都参与计算）：
输入 ──→ [FFN全部神经元] ──→ 输出

MoE模型（只激活部分专家）：
                    ┌──→ [Expert 0] ──┐
                    │                 │
输入 ──→ [Router] ──┼──→ [Expert 1] ──┼──→ [加权求和] ──→ 输出
                    │                 │
                    └──→ [Expert 2] ──┘

Router决定激活哪些Expert（通常2个）
```

**MoE的优势**：

- 总参数量很大（如8个Expert，每个Expert和原来一样大 → 8倍参数）
- 但每次计算只激活2个Expert → 计算量只增加25%
- 实现"大模型容量，小模型计算量"

#### EP的切分方式

```
假设有8个Expert，EP=4：

┌──────────┐  ┌──────────┐  ┌──────────┐  ┌──────────┐
│  GPU 0   │  │  GPU 1   │  │  GPU 2   │  │  GPU 3   │
│Expert 0,1│  │Expert 2,3│  │Expert 4,5│  │Expert 6,7│
└──────────┘  └──────────┘  └──────────┘  └──────────┘
```

#### EP的通信：AllToAll

MoE中，每个token可能需要发送到不同的Expert：

```
假设Batch有4个token，每个token要发送到2个Expert：

Token分布（Router输出）：
- Token 0 → Expert 1, 5
- Token 1 → Expert 3, 7
- Token 2 → Expert 0, 4
- Token 3 → Expert 2, 6

需要AllToAll通信：
┌────────────────────────────────────────────────────────┐
│                     AllToAll                           │
│  每个GPU发送自己的token到目标Expert所在的GPU            │
│  每个GPU接收其他GPU发来的需要本地Expert处理的token       │
└────────────────────────────────────────────────────────┘

GPU 0 (Expert 0,1) ←→ GPU 1 (Expert 2,3)
         ↕                    ↕
GPU 2 (Expert 4,5) ←→ GPU 3 (Expert 6,7)
```

#### EP通信量

```
发送通信量 = (EP-1)/EP × batch × seq × hidden × 2字节
接收通信量 = (EP-1)/EP × batch × seq × hidden × 2字节
总通信量 = 发送 + 接收 = 2 × (EP-1)/EP × batch × seq × hidden × 2字节

注：每个MoE层需要2次AllToAll（Expert前和Expert后）
```

#### 优点

- 自然适配MoE架构
- 可以部署超大规模MoE模型

#### 缺点

- 只适用于MoE模型
- AllToAll通信复杂，负载可能不均衡
- Expert选择不均匀可能导致热点

---

### 4.5 序列并行 (Sequence Parallelism, SP)

#### 核心思想

将**长序列**切分到多张GPU上处理。

```
原始序列：[token_0, token_1, token_2, ..., token_8191]  // 8K tokens

SP=4时：
GPU 0: [token_0    ~ token_2047]   // 处理0-2047
GPU 1: [token_2048 ~ token_4095]   // 处理2048-4095
GPU 2: [token_4096 ~ token_6143]   // 处理4096-6143
GPU 3: [token_6144 ~ token_8191]   // 处理6144-8191
```

#### 为什么需要SP？

1. **KV Cache太大**：长序列的KV Cache可能超过显存
2. **Attention计算复杂度**：O(seq²)，长序列计算量爆炸

#### SP的挑战

**Attention需要看到完整序列**：

```
Attention(Q, K, V) = softmax(Q × K^T / √d) × V

每个token需要和所有其他token计算attention
→ 需要跨GPU通信K和V
```

#### SP的通信

```
SP通信量 = (SP-1)/SP × batch × seq × hidden × 层数 × 2字节
```

#### 适用场景

- 超长序列（32K, 128K tokens）
- 单卡KV Cache放不下

---

### 4.6 并行策略对比总结

| 策略         | 切分维度         | 通信类型     | 通信频率    | 适用场景     |
| ------------ | ---------------- | ------------ | ----------- | ------------ |
| **DP** | 数据(batch)      | 无（推理时） | -           | 小模型高吞吐 |
| **TP** | 模型宽度(hidden) | AllReduce    | 每层2次     | 大模型低延迟 |
| **PP** | 模型深度(layers) | P2P          | 每stage边界 | 跨节点部署   |
| **EP** | 专家(experts)    | AllToAll     | 每MoE层2次  | MoE模型      |
| **SP** | 序列(seq_len)    | AllGather    | 每Attention | 超长序列     |

---

## 五、通信原语详解

并行策略需要GPU之间通信，通信通过**集合通信原语**实现。

### 5.1 什么是集合通信？

集合通信是**一组进程（GPU）共同参与**的通信模式，不同于点对点通信：

```
点对点通信（P2P）：
GPU 0 ──────────────→ GPU 1
       发送特定数据

集合通信（Collective）：
GPU 0 ←─┐
GPU 1 ←─┼── 所有GPU参与，按特定模式交换数据
GPU 2 ←─┼
GPU 3 ←─┘
```

### 5.2 AllReduce

**功能**：所有GPU的数据进行**归约**（如求和），结果**广播**到所有GPU。

```
初始状态：                  AllReduce(Sum)后：
GPU 0: [1, 2, 3, 4]        GPU 0: [10, 20, 30, 40]
GPU 1: [2, 4, 6, 8]   ──→  GPU 1: [10, 20, 30, 40]
GPU 2: [3, 6, 9, 12]       GPU 2: [10, 20, 30, 40]
GPU 3: [4, 8, 12, 16]      GPU 3: [10, 20, 30, 40]

结果 = 各GPU对应位置求和
```

**用途**：TP中同步各GPU的部分计算结果

**通信量**：

```
AllReduce通信量 = 2 × (n-1)/n × M

其中：
- n = 参与的GPU数量
- M = 数据大小（字节）
- 系数2是因为Ring AllReduce需要2轮（ReduceScatter + AllGather）
```

### 5.3 AllGather

**功能**：每个GPU有一部分数据，收集后**每个GPU都有完整数据**。

```
初始状态：              AllGather后：
GPU 0: [A]             GPU 0: [A, B, C, D]
GPU 1: [B]       ──→   GPU 1: [A, B, C, D]
GPU 2: [C]             GPU 2: [A, B, C, D]
GPU 3: [D]             GPU 3: [A, B, C, D]
```

**用途**：SP中收集各GPU的序列片段

**通信量**：

```
AllGather通信量 = (n-1)/n × M × n = (n-1) × M
```

### 5.4 ReduceScatter

**功能**：归约后**分散**到各GPU（每个GPU只得到结果的一部分）。

```
初始状态：                    ReduceScatter后：
GPU 0: [1,2,3,4]             GPU 0: [10]      (第0块的和)
GPU 1: [2,4,6,8]       ──→   GPU 1: [20]      (第1块的和)
GPU 2: [3,6,9,12]            GPU 2: [30]      (第2块的和)
GPU 3: [4,8,12,16]           GPU 3: [40]      (第3块的和)
```

**用途**：TP中的梯度同步（训练时）

**通信量**：

```
ReduceScatter通信量 = (n-1)/n × M
```

### 5.5 AllToAll

**功能**：每个GPU向每个其他GPU发送不同的数据块。

```
初始状态：                        AllToAll后：
GPU 0: [A0, A1, A2, A3]          GPU 0: [A0, B0, C0, D0]
GPU 1: [B0, B1, B2, B3]    ──→   GPU 1: [A1, B1, C1, D1]
GPU 2: [C0, C1, C2, C3]          GPU 2: [A2, B2, C2, D2]
GPU 3: [D0, D1, D2, D3]          GPU 3: [A3, B3, C3, D3]

X[i,j]发送到GPU j，成为结果的第i块
```

**用途**：EP中token路由到不同Expert

**通信量**：

```
AllToAll通信量 = 2 × (n-1)/n × M
（发送和接收各一次）
```

### 5.6 P2P (Point-to-Point)

**功能**：两个GPU之间直接发送数据。

```
GPU 0 ──────[数据]─────→ GPU 1
```

**用途**：PP中stage间传递激活值

**通信量**：

```
P2P通信量 = M（数据大小）
```

### 5.7 通信原语对比

| 原语          | 初始状态        | 结果状态            | 通信量        | 主要用途 |
| ------------- | --------------- | ------------------- | ------------- | -------- |
| AllReduce     | 各GPU有不同数据 | 所有GPU有相同结果   | 2(n-1)/n × M | TP同步   |
| AllGather     | 各GPU有一部分   | 所有GPU有完整数据   | (n-1) × M    | SP收集   |
| ReduceScatter | 各GPU有完整数据 | 各GPU有结果的一部分 | (n-1)/n × M  | 梯度同步 |
| AllToAll      | 各GPU有n块数据  | 重新分配到n个GPU    | 2(n-1)/n × M | EP路由   |
| P2P           | 发送方有数据    | 接收方有数据        | M             | PP传递   |

### 5.8 Ring算法示意

大多数集合通信使用**Ring算法**实现，将GPU组成环形：

```
Ring AllReduce（4个GPU）：

阶段1 - ReduceScatter：
GPU0 ──→ GPU1 ──→ GPU2 ──→ GPU3 ──→ GPU0
    数据块逐步累加

阶段2 - AllGather：
GPU0 ──→ GPU1 ──→ GPU2 ──→ GPU3 ──→ GPU0
    完整结果逐步广播

每个GPU只与相邻GPU通信，通信量均衡
```

---

## 六、部署方案设计与权衡

### 6.1 什么是部署方案？

**部署方案 = 并行策略的组合**

```
示例方案：DP=2, TP=4, PP=2

总GPU数 = DP × TP × PP = 2 × 4 × 2 = 16张

┌─────────────────────────────────────────────────────────┐
│                     DP Group 0                          │
│  ┌─────────────────────────┬─────────────────────────┐  │
│  │      PP Stage 0         │      PP Stage 1         │  │
│  │  ┌────┬────┬────┬────┐  │  ┌────┬────┬────┬────┐  │  │
│  │  │GPU0│GPU1│GPU2│GPU3│  │  │GPU4│GPU5│GPU6│GPU7│  │  │
│  │  └────┴────┴────┴────┘  │  └────┴────┴────┴────┘  │  │
│  │      TP Group 0         │      TP Group 1         │  │
│  └─────────────────────────┴─────────────────────────┘  │
└─────────────────────────────────────────────────────────┘
┌─────────────────────────────────────────────────────────┐
│                     DP Group 1                          │
│  ┌─────────────────────────┬─────────────────────────┐  │
│  │      PP Stage 0         │      PP Stage 1         │  │
│  │  ┌────┬────┬────┬────┐  │  ┌────┬────┬────┬────┐  │  │
│  │  │GPU8│GPU9│10 │11 │  │  │12 │13 │14 │15 │  │  │
│  │  └────┴────┴────┴────┘  │  └────┴────┴────┴────┘  │  │
│  │      TP Group 2         │      TP Group 3         │  │
│  └─────────────────────────┴─────────────────────────┘  │
└─────────────────────────────────────────────────────────┘
```

### 6.2 方案设计的约束条件

#### 硬约束（必须满足）

1. **显存约束**

   ```
   每卡显存需求 ≤ 可用显存

   每卡显存 = 模型参数/(TP×PP) + KV Cache + 激活值
   ```
2. **GPU数量约束**

   ```
   DP × TP × PP × EP × SP ≤ 总GPU数
   ```
3. **可整除约束**

   ```
   - 层数必须能被PP整除
   - Attention头数必须能被TP整除
   - Expert数必须能被EP整除
   ```

#### 软约束（影响性能）

1. **TP放在高带宽互联上**

   - TP通信频繁，需要NVLink级别带宽
   - 通常TP限制在单节点内（8卡以内）
2. **PP可以跨节点**

   - PP通信较少，可以使用较慢网络
   - 但要注意pipeline bubble
3. **DP优先节点间**

   - DP推理时无通信，放哪里都行

### 6.3 不同方案的权衡

#### 方案A：纯TP（TP=8, PP=1）

```
优点：
- 无pipeline bubble
- 延迟最低（单次请求）

缺点：
- 通信量大（每层2次AllReduce）
- 必须在单节点内
- TP=8时通信开销显著
```

#### 方案B：纯PP（TP=1, PP=8）

```
优点：
- 通信量小（只在边界P2P）
- 可以跨节点

缺点：
- pipeline bubble严重
- 吞吐量下降
- 延迟增加
```

#### 方案C：混合（TP=4, PP=2）

```
优点：
- 平衡通信和bubble
- TP在节点内，PP跨节点

缺点：
- 配置更复杂
- 需要仔细调优
```

### 6.4 如何选择最优方案？

#### 步骤1：计算最小并行度

```python
# 必须满足显存约束
min_parallelism = ceil(模型显存需求 / 单卡显存)
```

#### 步骤2：确定TP上限

```python
# TP受限于单节点GPU数和Attention头数
max_tp = min(节点内GPU数, num_attention_heads)
```

#### 步骤3：确定PP

```python
# PP = 总并行度 / TP
pp = ceil(min_parallelism / tp)
```

#### 步骤4：验证和调优

```python
# 检查：
1. 显存是否满足？
2. 通信延迟是否可接受？
3. pipeline bubble是否过大？
4. 吞吐量是否满足需求？
```

### 6.5 性能指标计算

#### 延迟估算

```
Prefill延迟 ≈ max(计算延迟, TP通信延迟, PP通信延迟)

计算延迟 = FLOPs / (峰值算力 × 利用率)
TP通信延迟 = 通信量 / 带宽 + 启动延迟
PP通信延迟 = 激活值大小 / 带宽 × (PP-1)

Decode延迟 ≈ 计算延迟 + 通信延迟（每token）

端到端延迟 = Prefill延迟 + Decode延迟 × 输出token数
```

#### 吞吐量估算

```
理论吞吐量 = batch_size × DP / 端到端延迟

实际吞吐量 = 理论吞吐量 × (1 - bubble比例) × 效率因子
```

#### 效率指标

```
计算利用率 = 实际FLOPs / 峰值FLOPs
显存利用率 = 已用显存 / 总显存
网络利用率 = 实际带宽 / 峰值带宽
```

---

## 七、实际案例分析

### 案例1：部署LLaMA-70B

**场景**：

- 模型：LLaMA-70B (70B参数，80层，8192 hidden)
- 硬件：8×H100 (80GB显存，NVLink互联)
- 需求：batch_size=8, seq_len=4096

**分析**：

```
1. 显存需求：
   - 模型：70B × 2字节 = 140GB
   - KV Cache：2 × 8 × 4096 × 80 × 8 × 128 × 2 = 104GB
   - 激活值：~10GB
   - 总计：~254GB

2. 最小并行度：
   254GB / 80GB ≈ 3.2 → 至少需要4卡

3. 方案选择：
   方案A: TP=8, PP=1
   - 每卡显存：140/8 + 104/8 + 10 ≈ 40.5GB ✓
   - 每层通信：2 × 7/8 × 8 × 4096 × 8192 × 2 ≈ 895MB
   - 总通信：895MB × 80 × 2 = 143GB
   - 通信延迟：143GB / 450GB/s ≈ 318ms

   方案B: TP=4, PP=2
   - 每卡显存：140/8 + 104/8 + 10 ≈ 40.5GB ✓
   - TP通信：895MB × 40 × 2 / 2 = 35.8GB（减半）
   - PP通信：8 × 4096 × 8192 × 2 = 512MB（边界传递）
   - 更好的通信/计算重叠

推荐：TP=4, PP=2
```

### 案例2：部署Mixtral-8x7B (MoE)

**场景**：

- 模型：Mixtral-8x7B (8个Expert，每个7B参数)
- 硬件：16×H100
- 需求：高吞吐量

**分析**：

```
1. 模型特点：
   - Dense参数：~2B（Attention等）
   - Expert参数：8 × 7B = 56B（但每次只激活2个）
   - 总参数：~47B（有参数共享）

2. 部署策略：
   - EP=8：每卡放1个Expert
   - TP=2：切分Dense部分
   - 总共：8 × 2 = 16卡

3. 通信分析：
   - TP通信：AllReduce，每层2次
   - EP通信：AllToAll，每MoE层2次
   - 需要高效的AllToAll实现

推荐：EP=8, TP=2（节点内TP，节点间EP）
```

### 案例3：超长序列场景

**场景**：

- 模型：LLaMA-7B
- 序列长度：128K tokens
- 硬件：4×A100 (40GB)

**分析**：

```
1. KV Cache爆炸：
   - 正常：2 × 1 × 128K × 32 × 32 × 128 × 2 = 64GB
   - 单卡放不下！

2. 解决方案：
   - 方案A: SP=4，序列切到4卡
   - 方案B: PP=4，KV Cache也切分
   - 方案C: 使用Flash Attention + 分块

推荐：根据具体需求选择，SP适合保持低延迟
```

---

## 八、总结与最佳实践

### 8.1 核心要点

1. **部署的本质**是将大模型切分到多个设备，并高效协调它们工作
2. **并行策略选择**取决于：

   - 模型大小（决定最小并行度）
   - 硬件拓扑（决定通信代价）
   - 性能目标（延迟 vs 吞吐）
3. **通信是关键瓶颈**，策略设计要最小化通信开销

### 8.2 最佳实践

| 场景         | 推荐策略       | 原因             |
| ------------ | -------------- | ---------------- |
| 小模型高吞吐 | DP only        | 无通信开销       |
| 大模型低延迟 | TP=4~8         | 最小化序列化     |
| 超大模型     | TP + PP        | 平衡显存和延迟   |
| MoE模型      | EP + TP        | 自然切分Expert   |
| 超长序列     | SP 或 特殊优化 | 解决KV Cache问题 |

### 8.3 常见陷阱

1. **TP过大**：TP=16时通信开销可能超过50%
2. **PP气泡**：micro-batch数量要远大于PP
3. **显存估算不准**：忘记KV Cache、激活值
4. **忽略网络拓扑**：跨节点TP会很慢

### 8.4 决策流程图

```
                    ┌─────────────────┐
                    │   模型大小？     │
                    └────────┬────────┘
                             │
              ┌──────────────┴──────────────┐
              ↓                              ↓
        单卡放得下                      单卡放不下
              │                              │
              ↓                              ↓
         使用纯DP                    计算最小并行度
              │                              │
              │               ┌──────────────┴──────────────┐
              │               ↓                              ↓
              │         ≤8（单节点内）              >8（需跨节点）
              │               │                              │
              │               ↓                              ↓
              │          优先用TP                     TP + PP混合
              │               │                              │
              │               └──────────────┬──────────────┘
              │                              │
              └──────────────┬───────────────┘
                             │
                             ↓
                    ┌─────────────────┐
                    │  是MoE模型吗？   │
                    └────────┬────────┘
                             │
              ┌──────────────┴──────────────┐
              ↓                              ↓
             是                             否
              │                              │
              ↓                              ↓
         加入EP策略                    方案确定
              │                              │
              └──────────────┬───────────────┘
                             │
                             ↓
                    ┌─────────────────┐
                    │ 验证显存和性能  │
                    └─────────────────┘
```

---

## 附录A：术语表

| 术语       | 英文              | 含义                             |
| ---------- | ----------------- | -------------------------------- |
| 参数       | Parameter         | 模型中可学习的数值               |
| 显存       | GPU Memory / VRAM | GPU的内存                        |
| 推理       | Inference         | 用训练好的模型生成输出           |
| 部署       | Deployment        | 将模型放到硬件上提供服务         |
| 延迟       | Latency           | 请求到响应的时间                 |
| 吞吐       | Throughput        | 单位时间处理的请求/token数       |
| 张量       | Tensor            | 多维数组，神经网络的基本数据结构 |
| 激活值     | Activation        | 神经网络前向传播的中间结果       |
| KV Cache   | Key-Value Cache   | 缓存历史token的K、V值            |
| NVLink     | -                 | NVIDIA GPU间的高速互联技术       |
| InfiniBand | IB                | 数据中心高速网络技术             |

## 附录B：常见模型参数

| 模型         | 参数量 | 层数 | Hidden | Heads | FP16显存 |
| ------------ | ------ | ---- | ------ | ----- | -------- |
| LLaMA-7B     | 7B     | 32   | 4096   | 32    | 14GB     |
| LLaMA-13B    | 13B    | 40   | 5120   | 40    | 26GB     |
| LLaMA-70B    | 70B    | 80   | 8192   | 64    | 140GB    |
| Mixtral-8x7B | 47B    | 32   | 4096   | 32    | 94GB     |
| GPT-3        | 175B   | 96   | 12288  | 96    | 350GB    |

## 附录C：常见硬件规格

| 硬件      | 显存  | 算力(FP16) | 显存带宽  | NVLink带宽 |
| --------- | ----- | ---------- | --------- | ---------- |
| A100-40GB | 40GB  | 312 TFLOPS | 1.5 TB/s  | 600 GB/s   |
| A100-80GB | 80GB  | 312 TFLOPS | 2.0 TB/s  | 600 GB/s   |
| H100-80GB | 80GB  | 990 TFLOPS | 3.35 TB/s | 900 GB/s   |
| H200      | 141GB | 990 TFLOPS | 4.8 TB/s  | 900 GB/s   |
