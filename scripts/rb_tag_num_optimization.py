#!/usr/bin/env python3
"""
RB_ONLY_TAGæ•°é‡ä¼˜åŒ–è„šæœ¬
ä½¿ç”¨Optunaä¼˜åŒ–æ¡†æ¶å¯»æ‰¾æ¨ªå‘ç¯å’Œçºµå‘ç¯RB_ONLYæ ‡ç­¾æ•°é‡çš„æœ€ä¼˜ç»„åˆ
"""

import os
import sys
import numpy as np
import matplotlib.pyplot as plt
import matplotlib as mpl
import time
import csv
import json
import traceback
import pandas as pd
from datetime import datetime
from typing import List, Tuple

# è®¾ç½®matplotlibä¸­æ–‡å­—ä½“æ”¯æŒ
plt.rcParams["font.sans-serif"] = ["SimHei", "Microsoft YaHei", "DejaVu Sans"]
plt.rcParams["axes.unicode_minus"] = False

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

from config.config import CrossRingConfig
from src.core.base_model_v2 import BaseModel
import optuna
from optuna.exceptions import TrialPruned
from optuna.trial import TrialState


# é…ç½®å‚æ•°
N_REPEATS = 1  # æ¯æ¬¡ä»¿çœŸé‡å¤æ¬¡æ•°
N_TRIALS = 100  # Optunaä¼˜åŒ–è¯•éªŒæ¬¡æ•°

# RB_ONLYæ ‡ç­¾æ•°é‡å‚æ•°èŒƒå›´
RB_TAG_PARAM_RANGES = {"RB_ONLY_TAG_NUM_HORIZONTAL": {"start": 0, "end": 14}, "RB_ONLY_TAG_NUM_VERTICAL": {"start": 0, "end": 56}}


def save_intermediate_result(study, trial, output_csv_path):
    """ä¿å­˜å·²å®Œæˆçš„trialåˆ°CSVæ–‡ä»¶"""
    records = []
    for t in study.trials:
        if t.state != TrialState.COMPLETE:
            continue
        rec = {
            "number": t.number,
            "value": t.values[0] if t.values else 0,
            "state": t.state.name,
        }
        rec.update(t.params)
        rec.update(t.user_attrs)
        records.append(rec)

    # ä¿å­˜CSV
    if records:
        pd.DataFrame(records).to_csv(output_csv_path, index=False)
        if trial.number % 10 == 0:
            print(f"å·²å®Œæˆ {len(records)} ä¸ªè¯•éªŒï¼Œä¸­é—´ç»“æœå·²ä¿å­˜åˆ°: {output_csv_path}")


def create_2d_heatmap(study_trials, save_dir):
    """åˆ›å»ºRB_ONLYæ ‡ç­¾æ•°é‡çš„2Dçƒ­åŠ›å›¾"""
    if not study_trials:
        return

    # æå–å®Œæˆçš„è¯•éªŒæ•°æ®
    h_tags = []
    v_tags = []
    bandwidths = []

    for trial in study_trials:
        if trial.state == TrialState.COMPLETE and trial.values:
            h_tags.append(trial.params.get("RB_ONLY_TAG_NUM_HORIZONTAL", 0))
            v_tags.append(trial.params.get("RB_ONLY_TAG_NUM_VERTICAL", 0))
            # ä»user_attrsä¸­è·å–å¸¦å®½æ•°æ®
            bandwidth = trial.user_attrs.get("mixed_avg_weighted_bw_mean", trial.values[0] if trial.values else 0)
            bandwidths.append(bandwidth)

    if len(bandwidths) < 3:
        print("æ•°æ®ç‚¹å¤ªå°‘ï¼Œæ— æ³•ç”Ÿæˆçƒ­åŠ›å›¾")
        return

    # åˆ›å»ºçƒ­åŠ›å›¾
    plt.figure(figsize=(12, 10))

    # åˆ›å»ºç½‘æ ¼æ’å€¼
    from scipy.interpolate import griddata

    h_range = np.arange(min(h_tags), max(h_tags) + 1)
    v_range = np.arange(min(v_tags), max(v_tags) + 1)
    H, V = np.meshgrid(h_range, v_range)

    # æ’å€¼åˆ°ç½‘æ ¼
    Z = griddata((h_tags, v_tags), bandwidths, (H, V), method="cubic", fill_value=0)

    # ç»˜åˆ¶çƒ­åŠ›å›¾
    im = plt.imshow(Z, cmap="YlGnBu", origin="lower", aspect="auto", extent=[min(h_tags), max(h_tags), min(v_tags), max(v_tags)])

    # æ·»åŠ æ•£ç‚¹æ˜¾ç¤ºå®é™…æ•°æ®ç‚¹
    scatter = plt.scatter(h_tags, v_tags, c=bandwidths, cmap="YlGnBu", s=50, edgecolors="black", alpha=0.8)

    plt.xlabel("æ¨ªå‘ç¯RB_ONLYæ ‡ç­¾æ•°é‡", fontsize=14)
    plt.ylabel("çºµå‘ç¯RB_ONLYæ ‡ç­¾æ•°é‡", fontsize=14)
    plt.title("RB_ONLYæ ‡ç­¾æ•°é‡ä¼˜åŒ–çƒ­åŠ›å›¾", fontsize=16)

    # æ·»åŠ é¢œè‰²æ¡
    cbar = plt.colorbar(im)
    cbar.set_label("å¸¦å®½æŒ‡æ ‡ (GB/s)", fontsize=12)

    # æ ‡æ³¨æœ€ä¼˜ç‚¹
    if bandwidths:
        best_idx = np.argmax(bandwidths)
        best_h = h_tags[best_idx]
        best_v = v_tags[best_idx]
        best_bw = bandwidths[best_idx]
        plt.scatter(best_h, best_v, c="blue", s=200, marker="*", label=f"æœ€ä¼˜ç‚¹({best_h},{best_v}): {best_bw:.3f}")
        plt.legend()

    plt.tight_layout()
    heatmap_path = os.path.join(save_dir, "rb_tag_optimization_heatmap.png")
    plt.savefig(heatmap_path, dpi=300, bbox_inches="tight")
    plt.close()
    print(f"çƒ­åŠ›å›¾å·²ä¿å­˜: {heatmap_path}")


def run_single_traffic(traffic_file, h_tags, v_tags, result_save_path):
    """è¿è¡Œå•ä¸ªtrafficæ–‡ä»¶çš„ä»¿çœŸ"""
    tot_bw_list = []

    for rpt in range(N_REPEATS):
        config = CrossRingConfig("../config/config2.json")
        config.TOPO_TYPE = "5x2"

        # è®¾ç½®è¦æµ‹è¯•çš„æ ‡ç­¾æ•°é‡
        config.RB_ONLY_TAG_NUM_HORIZONTAL = h_tags
        config.RB_ONLY_TAG_NUM_VERTICAL = v_tags

        # åˆ›å»ºä»¿çœŸå®ä¾‹
        sim = BaseModel(
            model_type="REQ_RSP",
            config=config,
            topo_type="5x2",
            traffic_file_path="../traffic/0617",
            traffic_config=traffic_file,
            result_save_path=result_save_path,
            verbose=0,  # å…³é—­è¯¦ç»†è¾“å‡º
            print_trace=0,
            plot_link_state=0,
            plot_flow_fig=0,
            plot_RN_BW_fig=0,
        )

        try:
            sim.initial()
            sim.end_time = 6000
            sim.print_interval = 2000
            sim.run()
            bw = sim.get_results().get("mixed_avg_weighted_bw", 0)
        except Exception as e:
            print(f"[{traffic_file}][RPT {rpt}] ä»¿çœŸå¤±è´¥ H:{h_tags}, V:{v_tags}")
            print(f"é”™è¯¯è¯¦æƒ…: {str(e)}")
            bw = 0

        tot_bw_list.append(bw)

    bw_mean = float(np.mean(tot_bw_list))
    bw_std = float(np.std(tot_bw_list))

    return {
        f"mixed_avg_weighted_bw_mean_{traffic_file[:-4]}": bw_mean,
        f"mixed_avg_weighted_bw_std_{traffic_file[:-4]}": bw_std,
    }


def run_simulation_with_tag_nums(h_tags: int, v_tags: int, traffic_files: List[str], traffic_weights: List[float], result_save_path: str) -> dict:
    """è¿è¡Œæ‰€æœ‰trafficæ–‡ä»¶å¹¶ç»¼åˆç»“æœ"""
    all_results = {}
    all_bw_means = []

    for traffic_file in traffic_files:
        try:
            result = run_single_traffic(traffic_file, h_tags, v_tags, os.path.join(result_save_path, f"h{h_tags}_v{v_tags}"))
            all_results.update(result)
            bw_mean = result[f"mixed_avg_weighted_bw_mean_{traffic_file[:-4]}"]
            all_bw_means.append(bw_mean)
        except Exception as e:
            print(f"å¤„ç†{traffic_file}æ—¶å‡ºé”™: {e}")
            all_bw_means.append(0)
            all_results[f"mixed_avg_weighted_bw_mean_{traffic_file[:-4]}"] = 0
            all_results[f"mixed_avg_weighted_bw_std_{traffic_file[:-4]}"] = 0

    # è®¡ç®—åŠ æƒå¹³å‡å¸¦å®½
    weighted_bw_mean = sum(bw * weight for bw, weight in zip(all_bw_means, traffic_weights))

    # è®¡ç®—æœ€å°å¸¦å®½ï¼ˆä¿è¯æ‰€æœ‰trafficéƒ½æœ‰åˆç†æ€§èƒ½ï¼‰
    min_bw_mean = min(all_bw_means) if all_bw_means else 0

    # è®¡ç®—å¸¦å®½æ–¹å·®ï¼ˆè¡¡é‡ä¸åŒtrafficé—´çš„ä¸€è‡´æ€§ï¼‰
    bw_variance = np.var(all_bw_means) if len(all_bw_means) > 1 else 0

    # æ·»åŠ ç»¼åˆæŒ‡æ ‡
    all_results.update(
        {
            "mixed_avg_weighted_bw_weighted_mean": weighted_bw_mean,
            "mixed_avg_weighted_bw_min": min_bw_mean,
            "mixed_avg_weighted_bw_variance": bw_variance,
            "RB_ONLY_TAG_NUM_HORIZONTAL": h_tags,
            "RB_ONLY_TAG_NUM_VERTICAL": v_tags,
        }
    )

    return all_results


def find_optimal_rb_tag_nums():
    """ä¸“é—¨ç”¨äºå¯»æ‰¾RB_ONLYæ ‡ç­¾æ•°é‡æœ€ä¼˜å‚æ•°çš„å‡½æ•°"""

    # Trafficæ–‡ä»¶é…ç½®
    traffic_files = ["W_5x2.txt"]  # å¯ä»¥æ·»åŠ æ›´å¤štrafficæ–‡ä»¶
    traffic_weights = [1.0]  # å¯¹åº”æƒé‡

    assert len(traffic_files) == len(traffic_weights), "trafficæ–‡ä»¶æ•°é‡å’Œæƒé‡æ•°é‡å¿…é¡»ä¸€è‡´"
    assert abs(sum(traffic_weights) - 1.0) < 1e-6, "æƒé‡æ€»å’Œå¿…é¡»ç­‰äº1"

    # ç»“æœä¿å­˜è·¯å¾„
    results_file_name = f"RB_TAG_NUM_optimization_{datetime.now().strftime('%m%d_%H%M')}"
    result_root_save_path = f"../Result/RB_Tag_Num_Optimization/{results_file_name}/"
    os.makedirs(result_root_save_path, exist_ok=True)
    output_csv = os.path.join(result_root_save_path, f"{results_file_name}.csv")

    # å‚æ•°èŒƒå›´
    h_start, h_end = RB_TAG_PARAM_RANGES["RB_ONLY_TAG_NUM_HORIZONTAL"]["start"], RB_TAG_PARAM_RANGES["RB_ONLY_TAG_NUM_HORIZONTAL"]["end"]
    v_start, v_end = RB_TAG_PARAM_RANGES["RB_ONLY_TAG_NUM_VERTICAL"]["start"], RB_TAG_PARAM_RANGES["RB_ONLY_TAG_NUM_VERTICAL"]["end"]

    def objective(trial):
        # é‡‡æ ·RB_ONLYæ ‡ç­¾æ•°é‡å‚æ•°
        h_tags = trial.suggest_int("RB_ONLY_TAG_NUM_HORIZONTAL", h_start, h_end)
        v_tags = trial.suggest_int("RB_ONLY_TAG_NUM_VERTICAL", v_start, v_end)

        results = run_simulation_with_tag_nums(h_tags, v_tags, traffic_files, traffic_weights, result_root_save_path)

        # è·å–åŠ æƒå¹³å‡å¸¦å®½
        weighted_bw = results["mixed_avg_weighted_bw_weighted_mean"]

        # ä¿å­˜åˆ°trial.user_attrsï¼Œä¾¿äºåæœŸåˆ†æ
        for k, v in results.items():
            trial.set_user_attr(k, v)

        return weighted_bw

    return objective, output_csv, traffic_files, traffic_weights, result_root_save_path


if __name__ == "__main__":
    print("=" * 60)
    print(f"å¼€å§‹RB_ONLYæ ‡ç­¾æ•°é‡ä¼˜åŒ– - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)

    # è·å–ä¼˜åŒ–å‡½æ•°å’Œé…ç½®
    objective, output_csv, traffic_files, traffic_weights, result_root_save_path = find_optimal_rb_tag_nums()

    print(f"ä¼˜åŒ–å‚æ•°: RB_ONLY_TAG_NUM_HORIZONTAL, RB_ONLY_TAG_NUM_VERTICAL")
    print(
        f"å‚æ•°èŒƒå›´: H:[{RB_TAG_PARAM_RANGES['RB_ONLY_TAG_NUM_HORIZONTAL']['start']}-{RB_TAG_PARAM_RANGES['RB_ONLY_TAG_NUM_HORIZONTAL']['end']}], V:[{RB_TAG_PARAM_RANGES['RB_ONLY_TAG_NUM_VERTICAL']['start']}-{RB_TAG_PARAM_RANGES['RB_ONLY_TAG_NUM_VERTICAL']['end']}]"
    )
    print(f"Trafficæ–‡ä»¶: {traffic_files}")
    print(f"æƒé‡: {traffic_weights}")
    print(f"è¯•éªŒæ¬¡æ•°: {N_TRIALS}")
    print(f"ç»“æœä¿å­˜è·¯å¾„: {result_root_save_path}")
    print("=" * 60)

    # åˆ›å»ºOptunaç ”ç©¶
    study = optuna.create_study(
        study_name="CrossRing_RB_TAG_NUM_BO",
        direction="maximize",
        sampler=optuna.samplers.NSGAIISampler(),
    )

    try:
        study.optimize(
            objective,
            n_trials=N_TRIALS,
            n_jobs=1,  # RBæ ‡ç­¾ä¼˜åŒ–é€šå¸¸ä¸²è¡Œæ‰§è¡Œæ¯”è¾ƒç¨³å®š
            show_progress_bar=True,
            callbacks=[lambda study, trial: save_intermediate_result(study, trial, output_csv)],
        )
    except KeyboardInterrupt:
        print("ä¼˜åŒ–è¢«ç”¨æˆ·ä¸­æ–­")

    # ä¿å­˜æœ€ç»ˆç»“æœ
    final_records = []
    for t in study.trials:
        if t.state != TrialState.COMPLETE:
            continue
        rec = {
            "number": t.number,
            "value": t.values[0] if t.values else 0,
            "state": t.state.name,
        }
        rec.update(t.params)
        rec.update(t.user_attrs)
        final_records.append(rec)

    if final_records:
        final_df = pd.DataFrame(final_records)
        final_df.to_csv(output_csv, index=False)

    print("\n" + "=" * 60)
    print("RB_ONLYæ ‡ç­¾æ•°é‡ä¼˜åŒ–å®Œæˆ!")
    if study.best_trials:
        best_trial = study.best_trials[0]
        print("æœ€ä½³æŒ‡æ ‡:", best_trial.values)
        print("æœ€ä½³æ ‡ç­¾æ•°é‡å‚æ•°:", best_trial.params)

        # æ˜¾ç¤ºæœ€ä½³ç»“æœçš„è¯¦ç»†ä¿¡æ¯
        print("\næœ€ä½³é…ç½®çš„è¯¦ç»†ç»“æœ:")
        for traffic_file in traffic_files:
            traffic_name = traffic_file[:-4]
            if f"mixed_avg_weighted_bw_mean_{traffic_name}" in best_trial.user_attrs:
                print(f"  {traffic_name}: {best_trial.user_attrs[f'mixed_avg_weighted_bw_mean_{traffic_name}']:.2f} GB/s")
        print(f"  åŠ æƒå¹³å‡: {best_trial.user_attrs.get('mixed_avg_weighted_bw_weighted_mean', 0):.2f} GB/s")
        print(f"  æœ€å°å€¼: {best_trial.user_attrs.get('mixed_avg_weighted_bw_min', 0):.2f} GB/s")
        print(f"  æ–¹å·®: {best_trial.user_attrs.get('mixed_avg_weighted_bw_variance', 0):.2f}")
        print(f"  æ¨ªå‘ç¯æ ‡ç­¾æ•°é‡: {best_trial.params.get('RB_ONLY_TAG_NUM_HORIZONTAL', 0)}")
        print(f"  çºµå‘ç¯æ ‡ç­¾æ•°é‡: {best_trial.params.get('RB_ONLY_TAG_NUM_VERTICAL', 0)}")

    # åˆ›å»ºå¯è§†åŒ–
    print("\næ­£åœ¨ç”Ÿæˆå¯è§†åŒ–...")
    try:
        vis_dir = os.path.join(result_root_save_path, "visualizations")
        os.makedirs(vis_dir, exist_ok=True)

        # ç”Ÿæˆ2Dçƒ­åŠ›å›¾
        create_2d_heatmap(study.trials, vis_dir)

        print(f"å¯è§†åŒ–å·²ç”Ÿæˆ: {vis_dir}/")

    except Exception as e:
        print(f"ç”Ÿæˆå¯è§†åŒ–å¤±è´¥: {e}")
        traceback.print_exc()

    # ä¿å­˜é…ç½®å’Œç ”ç©¶å¯¹è±¡
    config_data = {
        "optimization_target": "RB_ONLY_TAG_NUM_HORIZONTAL and RB_ONLY_TAG_NUM_VERTICAL",
        "traffic_files": traffic_files,
        "traffic_weights": traffic_weights,
        "param_ranges": RB_TAG_PARAM_RANGES,
        "n_trials": N_TRIALS,
        "n_repeats": N_REPEATS,
        "timestamp": datetime.now().isoformat(),
        "result_root_save_path": result_root_save_path,
    }

    config_file = os.path.join(result_root_save_path, "optimization_config.json")
    with open(config_file, "w", encoding="utf-8") as f:
        json.dump(config_data, f, indent=2, ensure_ascii=False)

    print("=" * 60)
    print(f"ğŸ“ ç»“æœæ–‡ä»¶:")
    print(f"  â€¢ CSVæ•°æ®: {output_csv}")
    print(f"  â€¢ é…ç½®æ–‡ä»¶: {config_file}")
    print(f"  â€¢ å¯è§†åŒ–: {result_root_save_path}/visualizations/")
    print("=" * 60)
