#!/usr/bin/env python3
"""
RB_ONLY_TAGæ•°é‡ä¼˜åŒ–è„šæœ¬
ä½¿ç”¨Optunaä¼˜åŒ–æ¡†æ¶å¯»æ‰¾æ¨ªå‘ç¯å’Œçºµå‘ç¯RB_ONLYæ ‡ç­¾æ•°é‡çš„æœ€ä¼˜ç»„åˆ

ä½¿ç”¨æ–¹æ³•:
1. é»˜è®¤Optunaä¼˜åŒ–æ¨¡å¼:
   python rb_tag_num_optimization.py

2. å‚æ•°èŒƒå›´åˆ†ææ¨¡å¼:
   python rb_tag_num_optimization.py range

å‚æ•°èŒƒå›´åˆ†ææ¨¡å¼ä¼šéå†æŒ‡å®šçš„å‚æ•°ç»„åˆèŒƒå›´ï¼Œç³»ç»Ÿæ€§åœ°æµ‹è¯•æ¯ä¸ªç»„åˆçš„æ€§èƒ½ï¼Œ
å¹¶ç”Ÿæˆè¯¦ç»†çš„æ€§èƒ½å¯¹æ¯”å’Œçƒ­åŠ›å›¾å¯è§†åŒ–ã€‚
"""

import os
import sys
import numpy as np
import matplotlib.pyplot as plt
import matplotlib as mpl
import time
import csv
import json
import traceback
import pandas as pd
import gc
import logging
import threading
from datetime import datetime
from typing import List, Tuple

# è®¾ç½®matplotlibä¸­æ–‡å­—ä½“æ”¯æŒ
plt.rcParams["font.sans-serif"] = ["SimHei", "Microsoft YaHei", "DejaVu Sans"]
plt.rcParams["axes.unicode_minus"] = False

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

from config.config import CrossRingConfig
from src.core.base_model_v2 import BaseModel
import optuna
from optuna.exceptions import TrialPruned
from optuna.trial import TrialState


# é…ç½®å‚æ•°
N_REPEATS = 1  # æ¯æ¬¡ä»¿çœŸé‡å¤æ¬¡æ•°
N_TRIALS = 200  # Optunaä¼˜åŒ–è¯•éªŒæ¬¡æ•°
SIMULATION_TIMEOUT = 300  # å•æ¬¡ä»¿çœŸè¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰

# RB_ONLYæ ‡ç­¾æ•°é‡å‚æ•°èŒƒå›´
RB_TAG_PARAM_RANGES = {"RB_ONLY_TAG_NUM_HORIZONTAL": {"start": -1, "end": 14}, "RB_ONLY_TAG_NUM_VERTICAL": {"start": -1, "end": 20}}

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s", handlers=[logging.FileHandler("rb_tag_optimization.log"), logging.StreamHandler()])
logger = logging.getLogger(__name__)


# è¶…æ—¶å¼‚å¸¸å¤„ç†
class SimulationTimeoutError(Exception):
    pass


class SimulationRunner:
    def __init__(self, timeout_seconds):
        self.timeout_seconds = timeout_seconds
        self.result = None
        self.exception = None
        self.completed = False

    def run_with_timeout(self, target_func, *args, **kwargs):
        """ä½¿ç”¨çº¿ç¨‹å®ç°è·¨å¹³å°è¶…æ—¶æ§åˆ¶"""

        def target():
            try:
                self.result = target_func(*args, **kwargs)
                self.completed = True
            except Exception as e:
                self.exception = e

        thread = threading.Thread(target=target)
        thread.daemon = True
        thread.start()
        thread.join(timeout=self.timeout_seconds)

        if thread.is_alive():
            # è¶…æ—¶äº†ï¼Œçº¿ç¨‹ä»åœ¨è¿è¡Œ
            raise SimulationTimeoutError(f"ä»¿çœŸè¶…æ—¶ ({self.timeout_seconds}ç§’)")

        if self.exception:
            raise self.exception

        if not self.completed:
            raise SimulationTimeoutError("ä»¿çœŸå¼‚å¸¸ç»ˆæ­¢")

        return self.result


def save_intermediate_result(study, trial, output_csv_path):
    """ä¿å­˜å·²å®Œæˆçš„trialåˆ°CSVæ–‡ä»¶"""
    records = []
    for t in study.trials:
        if t.state != TrialState.COMPLETE:
            continue
        rec = {
            "number": t.number,
            "value": t.values[0] if t.values else 0,
            "state": t.state.name,
        }
        rec.update(t.params)
        rec.update(t.user_attrs)
        records.append(rec)

    # ä¿å­˜CSV
    if records:
        pd.DataFrame(records).to_csv(output_csv_path, index=False)
        if trial.number % 10 == 0:
            print(f"å·²å®Œæˆ {len(records)} ä¸ªè¯•éªŒï¼Œä¸­é—´ç»“æœå·²ä¿å­˜åˆ°: {output_csv_path}")


def run_parameter_range_analysis(h_range, v_range, traffic_files, traffic_weights, result_save_path):
    """
    éå†æŒ‡å®šçš„å‚æ•°èŒƒå›´ï¼Œåˆ†ææ¯ä¸ªå‚æ•°ç»„åˆçš„æ€§èƒ½è¡¨ç°

    Args:
        h_range: æ¨ªå‘ç¯èŒƒå›´ï¼Œå¯ä»¥æ˜¯ (start, end) æˆ– [val1, val2, ...]
        v_range: çºµå‘ç¯èŒƒå›´ï¼Œå¯ä»¥æ˜¯ (start, end) æˆ– [val1, val2, ...]
        traffic_files: trafficæ–‡ä»¶åˆ—è¡¨
        traffic_weights: å¯¹åº”æƒé‡
        result_save_path: ç»“æœä¿å­˜è·¯å¾„

    Returns:
        DataFrame: åŒ…å«æ‰€æœ‰å‚æ•°ç»„åˆç»“æœçš„æ•°æ®æ¡†
    """
    logger.info("å¼€å§‹å‚æ•°èŒƒå›´åˆ†æ...")

    # å¤„ç†å‚æ•°èŒƒå›´
    if isinstance(h_range, tuple) and len(h_range) == 2:
        h_values = list(range(h_range[0], h_range[1] + 1))
    else:
        h_values = list(h_range)

    if isinstance(v_range, tuple) and len(v_range) == 2:
        v_values = list(range(v_range[0], v_range[1] + 1))
    else:
        v_values = list(v_range)

    logger.info(f"æ¨ªå‘ç¯æµ‹è¯•å€¼: {h_values}")
    logger.info(f"çºµå‘ç¯æµ‹è¯•å€¼: {v_values}")
    logger.info(f"æ€»è®¡æµ‹è¯•ç»„åˆæ•°: {len(h_values) * len(v_values)}")

    all_results = []
    total_combinations = len(h_values) * len(v_values)
    current_combination = 0

    for h_val in h_values:
        for v_val in v_values:
            current_combination += 1
            logger.info(f"æµ‹è¯•ç»„åˆ {current_combination}/{total_combinations}: H={h_val}, V={v_val}")

            try:
                result = run_simulation_with_tag_nums(h_val, v_val, traffic_files, traffic_weights, result_save_path)
                result["combination_index"] = current_combination
                all_results.append(result)

                # å®æ—¶è¾“å‡ºå½“å‰ç»“æœ
                weighted_bw = result.get("mixed_avg_weighted_bw_weighted_mean", 0)
                logger.info(f"ç»„åˆ H={h_val}, V={v_val} å®Œæˆï¼ŒåŠ æƒå¸¦å®½: {weighted_bw:.3f}")

            except Exception as e:
                logger.error(f"ç»„åˆ H={h_val}, V={v_val} å¤±è´¥: {e}")
                # åˆ›å»ºå¤±è´¥è®°å½•
                failed_result = {
                    "RB_ONLY_TAG_NUM_HORIZONTAL": h_val,
                    "RB_ONLY_TAG_NUM_VERTICAL": v_val,
                    "mixed_avg_weighted_bw_weighted_mean": 0,
                    "combination_index": current_combination,
                    "error": str(e),
                }
                for traffic_file in traffic_files:
                    traffic_name = traffic_file[:-4]
                    failed_result[f"mixed_avg_weighted_bw_mean_{traffic_name}"] = 0
                    failed_result[f"mixed_avg_weighted_bw_std_{traffic_name}"] = 0
                all_results.append(failed_result)

    # è½¬æ¢ä¸ºDataFrame
    results_df = pd.DataFrame(all_results)

    # ä¿å­˜ç»“æœ
    csv_path = os.path.join(result_save_path, f"parameter_range_analysis_{datetime.now().strftime('%m%d_%H%M')}.csv")
    results_df.to_csv(csv_path, index=False)
    logger.info(f"å‚æ•°èŒƒå›´åˆ†æç»“æœå·²ä¿å­˜: {csv_path}")

    # è¾“å‡ºåˆ†ææ‘˜è¦
    print_range_analysis_summary(results_df, h_values, v_values, traffic_files)

    return results_df


def print_range_analysis_summary(results_df, h_values, v_values, traffic_files):
    """æ‰“å°å‚æ•°èŒƒå›´åˆ†ææ‘˜è¦"""
    print("\n" + "=" * 80)
    print("å‚æ•°èŒƒå›´åˆ†ææ‘˜è¦")
    print("=" * 80)

    print(f"æ¨ªå‘ç¯æµ‹è¯•èŒƒå›´: {h_values}")
    print(f"çºµå‘ç¯æµ‹è¯•èŒƒå›´: {v_values}")
    print(f"æ€»æµ‹è¯•ç»„åˆæ•°: {len(results_df)}")

    # æ‰¾å‡ºæœ€ä¼˜é…ç½®
    if not results_df.empty and "mixed_avg_weighted_bw_weighted_mean" in results_df.columns:
        best_idx = results_df["mixed_avg_weighted_bw_weighted_mean"].idxmax()
        best_result = results_df.loc[best_idx]

        print(f"\næœ€ä¼˜é…ç½®:")
        print(f"  æ¨ªå‘ç¯: {best_result['RB_ONLY_TAG_NUM_HORIZONTAL']}")
        print(f"  çºµå‘ç¯: {best_result['RB_ONLY_TAG_NUM_VERTICAL']}")
        print(f"  åŠ æƒå¹³å‡å¸¦å®½: {best_result['mixed_avg_weighted_bw_weighted_mean']:.3f}")

        print(f"\nå„trafficæ€§èƒ½:")
        for traffic_file in traffic_files:
            traffic_name = traffic_file[:-4]
            bw_key = f"mixed_avg_weighted_bw_mean_{traffic_name}"
            if bw_key in best_result:
                print(f"  {traffic_name}: {best_result[bw_key]:.3f}")

        # æ€§èƒ½åˆ†å¸ƒç»Ÿè®¡
        print(f"\næ€§èƒ½åˆ†å¸ƒç»Ÿè®¡:")
        bw_col = "mixed_avg_weighted_bw_weighted_mean"
        print(f"  åŠ æƒå¸¦å®½èŒƒå›´: {results_df[bw_col].min():.3f} - {results_df[bw_col].max():.3f}")
        print(f"  åŠ æƒå¸¦å®½å¹³å‡: {results_df[bw_col].mean():.3f}")
        print(f"  åŠ æƒå¸¦å®½æ ‡å‡†å·®: {results_df[bw_col].std():.3f}")

        # Top 5 é…ç½®
        print(f"\nTop 5 é…ç½®:")
        top5 = results_df.nlargest(5, bw_col)
        for i, (idx, row) in enumerate(top5.iterrows(), 1):
            print(f"  {i}. H={row['RB_ONLY_TAG_NUM_HORIZONTAL']}, V={row['RB_ONLY_TAG_NUM_VERTICAL']}, BW={row[bw_col]:.3f}")

    print("=" * 80)


def create_enhanced_heatmap(results_df, save_dir):
    """åˆ›å»ºå¢å¼ºçš„çƒ­åŠ›å›¾ï¼Œæ”¯æŒå‚æ•°èŒƒå›´åˆ†æç»“æœ"""
    if results_df.empty:
        print("æ— æ•°æ®å¯ç”¨äºç”Ÿæˆçƒ­åŠ›å›¾")
        return

    # æå–æ•°æ®
    h_values = results_df["RB_ONLY_TAG_NUM_HORIZONTAL"].values
    v_values = results_df["RB_ONLY_TAG_NUM_VERTICAL"].values
    bw_values = results_df["mixed_avg_weighted_bw_weighted_mean"].values

    # åˆ›å»ºçƒ­åŠ›å›¾æ•°æ®
    h_unique = sorted(results_df["RB_ONLY_TAG_NUM_HORIZONTAL"].unique())
    v_unique = sorted(results_df["RB_ONLY_TAG_NUM_VERTICAL"].unique())

    # åˆ›å»ºç½‘æ ¼æ•°æ®
    heatmap_data = np.full((len(v_unique), len(h_unique)), np.nan)

    for _, row in results_df.iterrows():
        h_idx = h_unique.index(row["RB_ONLY_TAG_NUM_HORIZONTAL"])
        v_idx = v_unique.index(row["RB_ONLY_TAG_NUM_VERTICAL"])
        heatmap_data[v_idx, h_idx] = row["mixed_avg_weighted_bw_weighted_mean"]

    # åˆ›å»ºå›¾è¡¨
    plt.figure(figsize=(14, 10))

    # ç»˜åˆ¶çƒ­åŠ›å›¾
    im = plt.imshow(heatmap_data, cmap="YlGnBu", aspect="auto", origin="lower")

    # è®¾ç½®åæ ‡è½´
    plt.xticks(range(len(h_unique)), h_unique)
    plt.yticks(range(len(v_unique)), v_unique)
    plt.xlabel("æ¨ªå‘ç¯ Bubble Slotæ•°é‡", fontsize=14)
    plt.ylabel("çºµå‘ç¯ Bubble Slotæ•°é‡", fontsize=14)
    plt.title("å‚æ•°èŒƒå›´åˆ†æçƒ­åŠ›å›¾ (åŠ æƒå¹³å‡å¸¦å®½)", fontsize=16, fontweight="bold")

    # æ·»åŠ é¢œè‰²æ¡
    cbar = plt.colorbar(im, shrink=0.8)
    cbar.set_label("åŠ æƒå¹³å‡å¸¦å®½ (GB/s)", fontsize=12)

    # åœ¨ç½‘æ ¼ä¸Šæ ‡æ³¨æ•°å€¼ï¼ˆåªåœ¨é«˜æ€§èƒ½åŒºåŸŸï¼‰
    max_bw = np.nanmax(heatmap_data)
    threshold = max_bw * 0.85  # åªåœ¨85%ä»¥ä¸Šçš„åŒºåŸŸæ˜¾ç¤ºæ•°å€¼

    for i in range(len(v_unique)):
        for j in range(len(h_unique)):
            if not np.isnan(heatmap_data[i, j]) and heatmap_data[i, j] >= threshold:
                text_color = "white" if heatmap_data[i, j] < max_bw * 0.95 else "black"
                plt.text(j, i, f"{heatmap_data[i, j]:.2f}", ha="center", va="center", color=text_color, fontsize=9, fontweight="bold")

    # æ ‡è®°æœ€ä¼˜ç‚¹
    if not results_df.empty:
        best_idx = results_df["mixed_avg_weighted_bw_weighted_mean"].idxmax()
        best_row = results_df.loc[best_idx]
        best_h = best_row["RB_ONLY_TAG_NUM_HORIZONTAL"]
        best_v = best_row["RB_ONLY_TAG_NUM_VERTICAL"]
        best_bw = best_row["mixed_avg_weighted_bw_weighted_mean"]

        h_pos = h_unique.index(best_h)
        v_pos = v_unique.index(best_v)

        plt.scatter(h_pos, v_pos, c="red", s=300, marker="*", edgecolors="white", linewidth=2, label=f"æœ€ä¼˜ç‚¹({best_h},{best_v}): {best_bw:.3f}")
        plt.legend(loc="upper right")

    plt.tight_layout()

    # ä¿å­˜å›¾ç‰‡
    heatmap_path = os.path.join(save_dir, f"parameter_range_heatmap_{datetime.now().strftime('%m%d_%H%M')}.png")
    plt.savefig(heatmap_path, dpi=300, bbox_inches="tight")
    plt.close()
    print(f"å¢å¼ºçƒ­åŠ›å›¾å·²ä¿å­˜: {heatmap_path}")

    return heatmap_path


def create_2d_heatmap(study_trials, save_dir):
    """åˆ›å»ºRB_ONLYæ ‡ç­¾æ•°é‡çš„2Dçƒ­åŠ›å›¾"""
    if not study_trials:
        return

    # æå–å®Œæˆçš„è¯•éªŒæ•°æ®
    h_tags = []
    v_tags = []
    bandwidths = []

    for trial in study_trials:
        if trial.state == TrialState.COMPLETE and trial.values:
            h_tags.append(trial.params.get("RB_ONLY_TAG_NUM_HORIZONTAL", 0))
            v_tags.append(trial.params.get("RB_ONLY_TAG_NUM_VERTICAL", 0))
            # ä»user_attrsä¸­è·å–å¸¦å®½æ•°æ®
            bandwidth = trial.user_attrs.get("mixed_avg_weighted_bw_mean", trial.values[0] if trial.values else 0)
            bandwidths.append(bandwidth)

    if len(bandwidths) < 3:
        print("æ•°æ®ç‚¹å¤ªå°‘ï¼Œæ— æ³•ç”Ÿæˆçƒ­åŠ›å›¾")
        return

    # åˆ›å»ºçƒ­åŠ›å›¾
    plt.figure(figsize=(12, 10))

    # åˆ›å»ºç½‘æ ¼æ’å€¼
    from scipy.interpolate import griddata

    h_range = np.arange(min(h_tags), max(h_tags) + 1)
    v_range = np.arange(min(v_tags), max(v_tags) + 1)
    H, V = np.meshgrid(h_range, v_range)

    # æ’å€¼åˆ°ç½‘æ ¼
    Z = griddata((h_tags, v_tags), bandwidths, (H, V), method="cubic", fill_value=0)

    # ç»˜åˆ¶çƒ­åŠ›å›¾
    im = plt.imshow(Z, cmap="YlGnBu", origin="lower", aspect="auto", extent=[min(h_tags), max(h_tags), min(v_tags), max(v_tags)])

    # æ·»åŠ æ•£ç‚¹æ˜¾ç¤ºå®é™…æ•°æ®ç‚¹
    scatter = plt.scatter(h_tags, v_tags, c=bandwidths, cmap="YlGnBu", s=50, edgecolors="black", alpha=0.8)

    plt.xlabel("æ¨ªå‘ç¯Bubble slotæ•°é‡", fontsize=14)
    plt.ylabel("çºµå‘ç¯Bubble slotæ•°é‡", fontsize=14)
    plt.title("Bubble slotä¼˜åŒ–çƒ­åŠ›å›¾", fontsize=16)

    # æ·»åŠ é¢œè‰²æ¡
    cbar = plt.colorbar(im)
    cbar.set_label("å¸¦å®½ (GB/s)", fontsize=12)

    # æ ‡æ³¨æœ€ä¼˜ç‚¹
    if bandwidths:
        best_idx = np.argmax(bandwidths)
        best_h = h_tags[best_idx]
        best_v = v_tags[best_idx]
        best_bw = bandwidths[best_idx]
        plt.scatter(best_h, best_v, c="blue", s=200, marker="*", label=f"æœ€ä¼˜ç‚¹({best_h},{best_v}): {best_bw:.3f}")
        plt.legend()

    plt.tight_layout()
    heatmap_path = os.path.join(save_dir, "rb_tag_optimization_heatmap.png")
    plt.savefig(heatmap_path, dpi=300, bbox_inches="tight")
    plt.close()
    print(f"çƒ­åŠ›å›¾å·²ä¿å­˜: {heatmap_path}")


def run_single_traffic(traffic_file, h_tags, v_tags, result_save_path):
    """è¿è¡Œå•ä¸ªtrafficæ–‡ä»¶çš„ä»¿çœŸ"""
    tot_bw_list = []

    for rpt in range(N_REPEATS):
        logger.info(f"å¼€å§‹ä»¿çœŸ: {traffic_file}, H:{h_tags}, V:{v_tags}, é‡å¤:{rpt+1}/{N_REPEATS}")

        sim = None
        try:
            # éªŒè¯æ–‡ä»¶è·¯å¾„
            config_path = os.path.abspath("../config/config2.json")
            traffic_path = os.path.abspath("../traffic/0617")

            if not os.path.exists(config_path):
                raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
            if not os.path.exists(traffic_path):
                raise FileNotFoundError(f"æµé‡æ–‡ä»¶ç›®å½•ä¸å­˜åœ¨: {traffic_path}")

            config = CrossRingConfig(config_path)
            config.TOPO_TYPE = "5x2"

            # è®¾ç½®è¦æµ‹è¯•çš„æ ‡ç­¾æ•°é‡
            config.RB_ONLY_TAG_NUM_HORIZONTAL = h_tags
            config.RB_ONLY_TAG_NUM_VERTICAL = v_tags

            # åˆ›å»ºä»¿çœŸå®ä¾‹
            sim = BaseModel(
                model_type="REQ_RSP",
                config=config,
                topo_type="5x2",
                traffic_file_path=traffic_path,
                traffic_config=traffic_file,
                result_save_path=result_save_path,
                verbose=0,  # å…³é—­è¯¦ç»†è¾“å‡º
                print_trace=0,
                plot_link_state=0,
                plot_flow_fig=0,
                plot_RN_BW_fig=0,
            )

            # ä½¿ç”¨è·¨å¹³å°è¶…æ—¶æ§åˆ¶
            def run_simulation():
                sim.initial()
                sim.end_time = 6000
                sim.print_interval = 2000
                sim.run()
                return sim.get_results().get("mixed_avg_weighted_bw", 0)

            runner = SimulationRunner(SIMULATION_TIMEOUT)
            bw = runner.run_with_timeout(run_simulation)
            logger.info(f"ä»¿çœŸå®Œæˆ: {traffic_file}, H:{h_tags}, V:{v_tags}, BW:{bw:.3f}")

        except SimulationTimeoutError as e:
            logger.error(f"ä»¿çœŸè¶…æ—¶: {traffic_file}, H:{h_tags}, V:{v_tags}, é‡å¤:{rpt+1} - {str(e)}")
            bw = 0
        except Exception as e:
            logger.error(f"ä»¿çœŸå¤±è´¥: {traffic_file}, H:{h_tags}, V:{v_tags}, é‡å¤:{rpt+1}")
            logger.error(f"é”™è¯¯è¯¦æƒ…: {str(e)}")
            logger.error(f"å †æ ˆè·Ÿè¸ª: {traceback.format_exc()}")
            bw = 0
        finally:
            # å¼ºåˆ¶åƒåœ¾å›æ”¶
            if sim is not None:
                del sim
            gc.collect()

        tot_bw_list.append(bw)

    bw_mean = float(np.mean(tot_bw_list))
    bw_std = float(np.std(tot_bw_list))

    logger.info(f"Traffic {traffic_file} å®Œæˆ: å¹³å‡BW={bw_mean:.3f}, æ ‡å‡†å·®={bw_std:.3f}")

    return {
        f"mixed_avg_weighted_bw_mean_{traffic_file[:-4]}": bw_mean,
        f"mixed_avg_weighted_bw_std_{traffic_file[:-4]}": bw_std,
    }


def run_simulation_with_tag_nums(h_tags: int, v_tags: int, traffic_files: List[str], traffic_weights: List[float], result_save_path: str) -> dict:
    """è¿è¡Œæ‰€æœ‰trafficæ–‡ä»¶å¹¶ç»¼åˆç»“æœ"""
    logger.info(f"å¼€å§‹å‚æ•°ç»„åˆæµ‹è¯•: H={h_tags}, V={v_tags}")

    all_results = {}
    all_bw_means = []

    for traffic_file in traffic_files:
        try:
            result = run_single_traffic(traffic_file, h_tags, v_tags, os.path.join(result_save_path, f"h{h_tags}_v{v_tags}"))
            all_results.update(result)
            bw_mean = result[f"mixed_avg_weighted_bw_mean_{traffic_file[:-4]}"]
            all_bw_means.append(bw_mean)
        except Exception as e:
            logger.error(f"å¤„ç†{traffic_file}æ—¶å‡ºé”™: {e}")
            logger.error(f"å †æ ˆè·Ÿè¸ª: {traceback.format_exc()}")
            all_bw_means.append(0)
            all_results[f"mixed_avg_weighted_bw_mean_{traffic_file[:-4]}"] = 0
            all_results[f"mixed_avg_weighted_bw_std_{traffic_file[:-4]}"] = 0

    # è®¡ç®—åŠ æƒå¹³å‡å¸¦å®½
    weighted_bw_mean = sum(bw * weight for bw, weight in zip(all_bw_means, traffic_weights))

    # è®¡ç®—æœ€å°å¸¦å®½ï¼ˆä¿è¯æ‰€æœ‰trafficéƒ½æœ‰åˆç†æ€§èƒ½ï¼‰
    min_bw_mean = min(all_bw_means) if all_bw_means else 0

    # è®¡ç®—å¸¦å®½æ–¹å·®ï¼ˆè¡¡é‡ä¸åŒtrafficé—´çš„ä¸€è‡´æ€§ï¼‰
    bw_variance = np.var(all_bw_means) if len(all_bw_means) > 1 else 0

    # æ·»åŠ ç»¼åˆæŒ‡æ ‡
    all_results.update(
        {
            "mixed_avg_weighted_bw_weighted_mean": weighted_bw_mean,
            "mixed_avg_weighted_bw_min": min_bw_mean,
            "mixed_avg_weighted_bw_variance": bw_variance,
            "RB_ONLY_TAG_NUM_HORIZONTAL": h_tags,
            "RB_ONLY_TAG_NUM_VERTICAL": v_tags,
        }
    )

    logger.info(f"å‚æ•°ç»„åˆå®Œæˆ: H={h_tags}, V={v_tags}, åŠ æƒå¹³å‡BW={weighted_bw_mean:.3f}")
    return all_results


def find_optimal_rb_tag_nums():
    """ä¸“é—¨ç”¨äºå¯»æ‰¾RB_ONLYæ ‡ç­¾æ•°é‡æœ€ä¼˜å‚æ•°çš„å‡½æ•°"""

    # Trafficæ–‡ä»¶é…ç½®
    traffic_files = [
        "R_5x2.txt",
        "W_5x2.txt",
    ]
    traffic_weights = [0.5, 0.5]  # å¯¹åº”æƒé‡

    assert len(traffic_files) == len(traffic_weights), "trafficæ–‡ä»¶æ•°é‡å’Œæƒé‡æ•°é‡å¿…é¡»ä¸€è‡´"
    assert abs(sum(traffic_weights) - 1.0) < 1e-6, "æƒé‡æ€»å’Œå¿…é¡»ç­‰äº1"

    # ç»“æœä¿å­˜è·¯å¾„
    results_file_name = f"RB_TAG_NUM_optimization_{datetime.now().strftime('%m%d_%H%M')}"
    result_root_save_path = f"../Result/RB_Tag_Num_Optimization/{results_file_name}/"
    os.makedirs(result_root_save_path, exist_ok=True)
    output_csv = os.path.join(result_root_save_path, f"{results_file_name}.csv")

    # å‚æ•°èŒƒå›´
    h_start, h_end = RB_TAG_PARAM_RANGES["RB_ONLY_TAG_NUM_HORIZONTAL"]["start"], RB_TAG_PARAM_RANGES["RB_ONLY_TAG_NUM_HORIZONTAL"]["end"]
    v_start, v_end = RB_TAG_PARAM_RANGES["RB_ONLY_TAG_NUM_VERTICAL"]["start"], RB_TAG_PARAM_RANGES["RB_ONLY_TAG_NUM_VERTICAL"]["end"]

    def objective(trial):
        # é‡‡æ ·RB_ONLYæ ‡ç­¾æ•°é‡å‚æ•°
        h_tags = trial.suggest_int("RB_ONLY_TAG_NUM_HORIZONTAL", h_start, h_end)
        v_tags = trial.suggest_int("RB_ONLY_TAG_NUM_VERTICAL", v_start, v_end)

        results = run_simulation_with_tag_nums(h_tags, v_tags, traffic_files, traffic_weights, result_root_save_path)

        # è·å–åŠ æƒå¹³å‡å¸¦å®½
        weighted_bw = results["mixed_avg_weighted_bw_weighted_mean"]

        # ä¿å­˜åˆ°trial.user_attrsï¼Œä¾¿äºåæœŸåˆ†æ
        for k, v in results.items():
            trial.set_user_attr(k, v)

        return weighted_bw

    return objective, output_csv, traffic_files, traffic_weights, result_root_save_path


def run_range_analysis_mode():
    """è¿è¡Œå‚æ•°èŒƒå›´åˆ†ææ¨¡å¼"""
    logger.info("=" * 60)
    logger.info("å‚æ•°èŒƒå›´åˆ†ææ¨¡å¼")
    logger.info("=" * 60)

    # é…ç½®å‚æ•°èŒƒå›´
    # å¯ä»¥æ ¹æ®éœ€è¦ä¿®æ”¹è¿™äº›èŒƒå›´
    h_range = (0, 14)  # æ¨ªå‘ç¯èŒƒå›´ 1-10
    v_range = (0, 30)  # çºµå‘ç¯èŒƒå›´ 1-15

    # ä¹Ÿå¯ä»¥ä½¿ç”¨åˆ—è¡¨å½¢å¼æŒ‡å®šç‰¹å®šå€¼
    # h_range = [1, 3, 5, 7, 9]
    # v_range = [2, 5, 8, 12, 15]

    traffic_files = ["R_5x2.txt", "W_5x2.txt"]
    traffic_weights = [0.5, 0.5]

    # ç»“æœä¿å­˜è·¯å¾„
    results_file_name = f"RB_TAG_NUM_range_analysis_{datetime.now().strftime('%m%d_%H%M')}"
    result_root_save_path = f"../Result/RB_Tag_Num_Optimization/{results_file_name}/"
    os.makedirs(result_root_save_path, exist_ok=True)

    logger.info(f"æ¨ªå‘ç¯èŒƒå›´: {h_range}")
    logger.info(f"çºµå‘ç¯èŒƒå›´: {v_range}")
    logger.info(f"Trafficæ–‡ä»¶: {traffic_files}")
    logger.info(f"æƒé‡: {traffic_weights}")
    logger.info(f"ç»“æœä¿å­˜è·¯å¾„: {result_root_save_path}")

    # è¿è¡Œå‚æ•°èŒƒå›´åˆ†æ
    results_df = run_parameter_range_analysis(h_range, v_range, traffic_files, traffic_weights, result_root_save_path)

    # ç”Ÿæˆå¢å¼ºçƒ­åŠ›å›¾
    if not results_df.empty:
        vis_dir = os.path.join(result_root_save_path, "visualizations")
        os.makedirs(vis_dir, exist_ok=True)
        create_enhanced_heatmap(results_df, vis_dir)

    return results_df, result_root_save_path


if __name__ == "__main__":
    # é€‰æ‹©è¿è¡Œæ¨¡å¼
    import sys

    # mode = "optuna"  # é»˜è®¤ä½¿ç”¨optunaä¼˜åŒ–
    mode = "range"
    # if len(sys.argv) > 1:
    # mode = sys.argv[1].lower()

    if mode == "range":
        # å‚æ•°èŒƒå›´åˆ†ææ¨¡å¼
        try:
            logger.info("å¯åŠ¨å‚æ•°èŒƒå›´åˆ†ææ¨¡å¼...")
            results_df, result_save_path = run_range_analysis_mode()
            logger.info("å‚æ•°èŒƒå›´åˆ†æå®Œæˆ!")
        except Exception as e:
            logger.error(f"å‚æ•°èŒƒå›´åˆ†æå¤±è´¥: {e}")
            logger.error(f"å †æ ˆè·Ÿè¸ª: {traceback.format_exc()}")
            sys.exit(1)
    else:
        # é»˜è®¤çš„Optunaä¼˜åŒ–æ¨¡å¼
        try:
            logger.info("=" * 60)
            logger.info(f"å¼€å§‹RB_ONLYæ ‡ç­¾æ•°é‡ä¼˜åŒ– - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            logger.info("=" * 60)

            # è·å–ä¼˜åŒ–å‡½æ•°å’Œé…ç½®
            objective, output_csv, traffic_files, traffic_weights, result_root_save_path = find_optimal_rb_tag_nums()

            logger.info(f"ä¼˜åŒ–å‚æ•°: RB_ONLY_TAG_NUM_HORIZONTAL, RB_ONLY_TAG_NUM_VERTICAL")
            logger.info(
                f"å‚æ•°èŒƒå›´: H:[{RB_TAG_PARAM_RANGES['RB_ONLY_TAG_NUM_HORIZONTAL']['start']}-{RB_TAG_PARAM_RANGES['RB_ONLY_TAG_NUM_HORIZONTAL']['end']}], V:[{RB_TAG_PARAM_RANGES['RB_ONLY_TAG_NUM_VERTICAL']['start']}-{RB_TAG_PARAM_RANGES['RB_ONLY_TAG_NUM_VERTICAL']['end']}]"
            )
            logger.info(f"Trafficæ–‡ä»¶: {traffic_files}")
            logger.info(f"æƒé‡: {traffic_weights}")
            logger.info(f"è¯•éªŒæ¬¡æ•°: {N_TRIALS}")
            logger.info(f"ä»¿çœŸè¶…æ—¶: {SIMULATION_TIMEOUT}ç§’")
            logger.info(f"ç»“æœä¿å­˜è·¯å¾„: {result_root_save_path}")
            logger.info("=" * 60)

            # åˆ›å»ºOptunaç ”ç©¶
            study = optuna.create_study(
                study_name="CrossRing_RB_TAG_NUM_BO",
                direction="maximize",
                sampler=optuna.samplers.NSGAIISampler(),
            )

            try:
                study.optimize(
                    objective,
                    n_trials=N_TRIALS,
                    n_jobs=1,  # RBæ ‡ç­¾ä¼˜åŒ–é€šå¸¸ä¸²è¡Œæ‰§è¡Œæ¯”è¾ƒç¨³å®š
                    show_progress_bar=True,
                    callbacks=[lambda study, trial: save_intermediate_result(study, trial, output_csv)],
                )
            except KeyboardInterrupt:
                logger.warning("ä¼˜åŒ–è¢«ç”¨æˆ·ä¸­æ–­")
            except Exception as e:
                logger.error(f"ä¼˜åŒ–è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
                logger.error(f"å †æ ˆè·Ÿè¸ª: {traceback.format_exc()}")
        except Exception as e:
            logger.error(f"ç¨‹åºå¯åŠ¨å¤±è´¥: {e}")
            logger.error(f"å †æ ˆè·Ÿè¸ª: {traceback.format_exc()}")
            sys.exit(1)

        # ä¿å­˜æœ€ç»ˆç»“æœ
        final_records = []
        for t in study.trials:
            if t.state != TrialState.COMPLETE:
                continue
            rec = {
                "number": t.number,
                "value": t.values[0] if t.values else 0,
                "state": t.state.name,
            }
            rec.update(t.params)
            rec.update(t.user_attrs)
            final_records.append(rec)

        if final_records:
            final_df = pd.DataFrame(final_records)
            final_df.to_csv(output_csv, index=False)

        print("\n" + "=" * 60)
        print("RB_ONLYæ ‡ç­¾æ•°é‡ä¼˜åŒ–å®Œæˆ!")
        if study.best_trials:
            best_trial = study.best_trials[0]
            print("æœ€ä½³æŒ‡æ ‡:", best_trial.values)
            print("æœ€ä½³æ ‡ç­¾æ•°é‡å‚æ•°:", best_trial.params)

            # æ˜¾ç¤ºæœ€ä½³ç»“æœçš„è¯¦ç»†ä¿¡æ¯
            print("\næœ€ä½³é…ç½®çš„è¯¦ç»†ç»“æœ:")
            for traffic_file in traffic_files:
                traffic_name = traffic_file[:-4]
                if f"mixed_avg_weighted_bw_mean_{traffic_name}" in best_trial.user_attrs:
                    print(f"  {traffic_name}: {best_trial.user_attrs[f'mixed_avg_weighted_bw_mean_{traffic_name}']:.2f} GB/s")
            print(f"  åŠ æƒå¹³å‡: {best_trial.user_attrs.get('mixed_avg_weighted_bw_weighted_mean', 0):.2f} GB/s")
            print(f"  æœ€å°å€¼: {best_trial.user_attrs.get('mixed_avg_weighted_bw_min', 0):.2f} GB/s")
            print(f"  æ–¹å·®: {best_trial.user_attrs.get('mixed_avg_weighted_bw_variance', 0):.2f}")
            print(f"  æ¨ªå‘ç¯æ ‡ç­¾æ•°é‡: {best_trial.params.get('RB_ONLY_TAG_NUM_HORIZONTAL', 0)}")
            print(f"  çºµå‘ç¯æ ‡ç­¾æ•°é‡: {best_trial.params.get('RB_ONLY_TAG_NUM_VERTICAL', 0)}")

        # åˆ›å»ºå¯è§†åŒ–
        print("\næ­£åœ¨ç”Ÿæˆå¯è§†åŒ–...")
        try:
            vis_dir = os.path.join(result_root_save_path, "visualizations")
            os.makedirs(vis_dir, exist_ok=True)

            # ç”Ÿæˆ2Dçƒ­åŠ›å›¾
            create_2d_heatmap(study.trials, vis_dir)

            print(f"å¯è§†åŒ–å·²ç”Ÿæˆ: {vis_dir}/")

        except Exception as e:
            print(f"ç”Ÿæˆå¯è§†åŒ–å¤±è´¥: {e}")
            traceback.print_exc()

        # ä¿å­˜é…ç½®å’Œç ”ç©¶å¯¹è±¡
        config_data = {
            "optimization_target": "RB_ONLY_TAG_NUM_HORIZONTAL and RB_ONLY_TAG_NUM_VERTICAL",
            "traffic_files": traffic_files,
            "traffic_weights": traffic_weights,
            "param_ranges": RB_TAG_PARAM_RANGES,
            "n_trials": N_TRIALS,
            "n_repeats": N_REPEATS,
            "timestamp": datetime.now().isoformat(),
            "result_root_save_path": result_root_save_path,
        }

        config_file = os.path.join(result_root_save_path, "optimization_config.json")
        with open(config_file, "w", encoding="utf-8") as f:
            json.dump(config_data, f, indent=2, ensure_ascii=False)

        print("=" * 60)
        print(f"ğŸ“ ç»“æœæ–‡ä»¶:")
        print(f"  â€¢ CSVæ•°æ®: {output_csv}")
        print(f"  â€¢ é…ç½®æ–‡ä»¶: {config_file}")
        print(f"  â€¢ å¯è§†åŒ–: {result_root_save_path}/visualizations/")
        print("=" * 60)
