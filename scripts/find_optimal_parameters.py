import sys
import os

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.noc import *
from src.utils.component import Flit, Network, Node
from config.config import CrossRingConfig
import numpy as np
import itertools
from joblib import Parallel, delayed
from tqdm import tqdm
import optuna  # Bayesian optimization library
import pandas as pd
import csv
import traceback
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import json
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import plotly.express as px

from optuna.exceptions import TrialPruned
from optuna.trial import TrialState
from scipy import stats
from sklearn.ensemble import RandomForestRegressor
from sklearn.feature_selection import mutual_info_regression

# ä½¿ç”¨çš„ CPU æ ¸å¿ƒæ•°ï¼›-1 è¡¨ç¤ºå…¨éƒ¨æ ¸å¿ƒ
N_JOBS = 1
# æ¯ä¸ªå‚æ•°ç»„åˆé‡å¤ä»¿çœŸæ¬¡æ•°ï¼Œç”¨äºå¹³æ»‘éšæœº latency å½±å“
N_REPEATS = 1  # å‡å°‘é‡å¤æ¬¡æ•°ï¼Œå› ä¸ºè¦æµ‹è¯•å¤šä¸ªtraffic
N_TRIALS = 300

# å…¨å±€å˜é‡ç”¨äºå­˜å‚¨å¯è§†åŒ–æ•°æ®
visualization_data = {"trials": [], "progress": [], "pareto_data": [], "param_importance": {}, "convergence": []}


def create_parameter_impact_plot(trials, traffic_files, save_dir):
    """å¢å¼ºç‰ˆå‚æ•°å½±å“åˆ†æå›¾"""
    if not trials:
        return

    # è·å–å‚æ•°å’Œæ€§èƒ½æ•°æ®
    param_names = list(trials[0].params.keys())
    traffic_names = [tf[:-4] for tf in traffic_files]

    # å‡†å¤‡æ•°æ®
    param_data = {param: [] for param in param_names}
    performance_data = {traffic: [] for traffic in traffic_names}
    weighted_performance = []

    for trial in trials:
        if trial.values is not None:
            # å‚æ•°æ•°æ®
            for param in param_names:
                param_data[param].append(trial.params[param])

            # æ€§èƒ½æ•°æ®
            for traffic in traffic_names:
                key = f"Total_sum_BW_mean_{traffic}"
                performance_data[traffic].append(trial.user_attrs.get(key, 0))

            weighted_performance.append(trial.user_attrs.get("Total_sum_BW_weighted_mean", 0))

    # 1. å‚æ•°æ•æ„Ÿæ€§åˆ†æçƒ­åŠ›å›¾
    fig1 = create_parameter_sensitivity_heatmap(param_data, performance_data, traffic_names, param_names)
    fig1.write_html(os.path.join(save_dir, "parameter_sensitivity_heatmap.html"))

    # 2. å‚æ•°å½±å“åŠ›æ•£ç‚¹å›¾çŸ©é˜µ
    fig2 = create_parameter_scatter_matrix(param_data, weighted_performance, param_names)
    fig2.write_html(os.path.join(save_dir, "parameter_scatter_matrix.html"))

    # 3. å‚æ•°ååŒæ•ˆåº”åˆ†æ
    fig3 = create_parameter_synergy_analysis(param_data, weighted_performance, param_names)
    fig3.write_html(os.path.join(save_dir, "parameter_synergy_analysis.html"))


def create_parameter_sensitivity_heatmap(param_data, performance_data, traffic_names, param_names):
    """åˆ›å»ºå‚æ•°æ•æ„Ÿæ€§çƒ­åŠ›å›¾"""
    from scipy import stats

    # è®¡ç®—ç›¸å…³ç³»æ•°çŸ©é˜µ
    correlation_matrix: np.ndarray = np.zeros((len(param_names), len(traffic_names)))

    for i, param in enumerate(param_names):
        for j, traffic in enumerate(traffic_names):
            if len(param_data[param]) > 1 and len(performance_data[traffic]) > 1:
                # æ£€æŸ¥æ˜¯å¦ä¸ºå¸¸æ•°è¾“å…¥
                param_std = np.std(param_data[param])
                perf_std = np.std(performance_data[traffic])
                if param_std > 1e-10 and perf_std > 1e-10:  # é¿å…å¸¸æ•°è¾“å…¥
                    try:
                        corr, _ = stats.pearsonr(param_data[param], performance_data[traffic])
                        correlation_matrix[i, j] = corr if not np.isnan(corr) else 0
                    except:
                        correlation_matrix[i, j] = 0
                else:
                    correlation_matrix[i, j] = 0

    fig = go.Figure(
        data=go.Heatmap(
            z=correlation_matrix,
            x=traffic_names,
            y=param_names,
            colorscale="RdBu",
            zmid=0,
            text=np.round(correlation_matrix, 3),
            texttemplate="%{text}",
            textfont={"size": 12},
            hoverongaps=False,
            colorbar=dict(title="ç›¸å…³ç³»æ•°"),
        )
    )

    fig.update_layout(title="å‚æ•°å¯¹ä¸åŒTrafficæ€§èƒ½çš„æ•æ„Ÿæ€§åˆ†æ", xaxis_title="Trafficç±»å‹", yaxis_title="å‚æ•°", height=600, width=800)

    return fig


def create_parameter_scatter_matrix(param_data, performance, param_names):
    """åˆ›å»ºå‚æ•°å½±å“æ•£ç‚¹å›¾çŸ©é˜µ"""
    n_params = len(param_names)
    cols = min(3, n_params)
    rows = (n_params + cols - 1) // cols

    fig = make_subplots(rows=rows, cols=cols, subplot_titles=[f"{param} vs æ€§èƒ½" for param in param_names], vertical_spacing=0.08, horizontal_spacing=0.08)

    for i, param in enumerate(param_names):
        row = i // cols + 1
        col = i % cols + 1

        x_vals = param_data[param]
        y_vals = performance

        # æ·»åŠ æ•£ç‚¹å›¾
        fig.add_trace(
            go.Scatter(x=x_vals, y=y_vals, mode="markers", marker=dict(size=6, color=y_vals, colorscale="Viridis", opacity=0.7, line=dict(width=1, color="black")), name=param, showlegend=False),
            row=row,
            col=col,
        )

        # æ·»åŠ è¶‹åŠ¿çº¿
        if len(x_vals) > 2:
            try:
                z = np.polyfit(x_vals, y_vals, 1)
                p = np.poly1d(z)
                x_trend = np.linspace(min(x_vals), max(x_vals), 100)
                y_trend = p(x_trend)

                fig.add_trace(go.Scatter(x=x_trend, y=y_trend, mode="lines", line=dict(color="red", width=2), name=f"{param}_trend", showlegend=False), row=row, col=col)
            except:
                pass

    fig.update_layout(title="å‚æ•°å¯¹æ€§èƒ½çš„ä¸ªä½“å½±å“åˆ†æ", height=300 * rows, width=1200)

    return fig


def create_parameter_synergy_analysis(param_data, performance, param_names):
    """åˆ›å»ºå‚æ•°ååŒæ•ˆåº”åˆ†æ"""
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.feature_selection import mutual_info_regression

    # ä½¿ç”¨éšæœºæ£®æ—åˆ†æå‚æ•°é‡è¦æ€§å’Œäº¤äº’æ•ˆåº”
    X = np.array([param_data[param] for param in param_names]).T
    y = np.array(performance)

    if len(X) < 10:
        # æ•°æ®å¤ªå°‘ï¼Œåˆ›å»ºç®€å•çš„ç›¸å…³æ€§åˆ†æ
        return create_simple_correlation_plot(param_data, performance, param_names)

    # éšæœºæ£®æ—ç‰¹å¾é‡è¦æ€§
    rf = RandomForestRegressor(n_estimators=100, random_state=42)
    rf.fit(X, y)
    feature_importance = rf.feature_importances_

    # åˆ›å»ºå­å›¾
    fig = make_subplots(
        rows=2, cols=2, subplot_titles=("å‚æ•°é‡è¦æ€§æ’å", "å‚æ•°äº¤äº’å¼ºåº¦", "å‚æ•°èšç±»åˆ†æ", "ååŒæ•ˆåº”ç½‘ç»œ"), specs=[[{"type": "bar"}, {"type": "heatmap"}], [{"type": "scatter"}, {"type": "scatter"}]]
    )

    # 1. å‚æ•°é‡è¦æ€§æ’å
    sorted_idx = np.argsort(feature_importance)[::-1]
    fig.add_trace(
        go.Bar(x=[param_names[i] for i in sorted_idx], y=[feature_importance[i] for i in sorted_idx], marker=dict(color=feature_importance[sorted_idx], colorscale="Viridis"), name="é‡è¦æ€§"),
        row=1,
        col=1,
    )

    # 2. å‚æ•°é—´ç›¸å…³æ€§çƒ­åŠ›å›¾
    param_corr = np.corrcoef(X.T)
    fig.add_trace(go.Heatmap(z=param_corr, x=param_names, y=param_names, colorscale="RdBu", zmid=0, showscale=False), row=1, col=2)

    fig.update_layout(title="å‚æ•°ååŒæ•ˆåº”æ·±åº¦åˆ†æ", height=800, width=1200)

    return fig


def create_simple_correlation_plot(param_data, performance, param_names):
    """æ•°æ®è¾ƒå°‘æ—¶çš„ç®€å•ç›¸å…³æ€§åˆ†æ"""
    from scipy import stats

    correlations = []
    for param in param_names:
        if len(param_data[param]) > 1:
            corr, _ = stats.pearsonr(param_data[param], performance)
            correlations.append(corr if not np.isnan(corr) else 0)
        else:
            correlations.append(0)

    fig = go.Figure(data=[go.Bar(x=param_names, y=correlations, marker=dict(color=correlations, colorscale="RdBu", colorbar=dict(title="ç›¸å…³ç³»æ•°")))])

    fig.update_layout(title="å‚æ•°ä¸æ€§èƒ½çš„ç›¸å…³æ€§åˆ†æ", xaxis_title="å‚æ•°", yaxis_title="ç›¸å…³ç³»æ•°", height=500)

    return fig


def create_enhanced_optimization_insight(study, vis_dir):
    """å¢å¼ºç‰ˆä¼˜åŒ–è¿‡ç¨‹æ·±åº¦æ´å¯Ÿ"""
    complete_trials = [t for t in study.trials if t.state.name == "COMPLETE"]

    if len(complete_trials) < 10:
        return

    # å‡†å¤‡æ•°æ®
    trial_numbers = [t.number for t in complete_trials]
    objective_values = [t.values[0] if t.values else 0 for t in complete_trials]
    param_names = list(complete_trials[0].params.keys()) if complete_trials else []

    fig = make_subplots(
        rows=2,
        cols=2,
        subplot_titles=("æ¢ç´¢ä¸åˆ©ç”¨å¹³è¡¡åˆ†æ", "å‚æ•°è¿›åŒ–è¶‹åŠ¿", "æ€§èƒ½çªç ´ç‚¹è¯†åˆ«", "ä¼˜åŒ–æ•ˆç‡åˆ†æ"),
        specs=[[{"secondary_y": True}, {"secondary_y": False}], [{"secondary_y": False}, {"secondary_y": False}]],
    )

    # 1. æ¢ç´¢ä¸åˆ©ç”¨å¹³è¡¡åˆ†æ
    exploration_scores, exploitation_scores = analyze_exploration_exploitation(complete_trials)

    fig.add_trace(go.Scatter(x=trial_numbers, y=exploration_scores, mode="lines+markers", name="æ¢ç´¢åº¦", line=dict(color="blue", width=2), marker=dict(size=4)), row=1, col=1)

    fig.add_trace(go.Scatter(x=trial_numbers, y=exploitation_scores, mode="lines+markers", name="åˆ©ç”¨åº¦", line=dict(color="red", width=2), marker=dict(size=4)), row=1, col=1, secondary_y=True)

    # 2. å‚æ•°è¿›åŒ–è¶‹åŠ¿
    if param_names:
        param_evolution = [trial.params.get(param_names[0], 0) for trial in complete_trials]
        fig.add_trace(go.Scatter(x=trial_numbers, y=param_evolution, mode="lines+markers", name=f"{param_names[0]} è¿›åŒ–", line=dict(color="green", width=2), marker=dict(size=4)), row=1, col=2)

    # 3. æ€§èƒ½çªç ´ç‚¹è¯†åˆ«
    breakthrough_points = identify_breakthrough_points(objective_values, trial_numbers)

    fig.add_trace(go.Scatter(x=trial_numbers, y=objective_values, mode="lines+markers", name="æ€§èƒ½è½¨è¿¹", line=dict(color="gray", width=1), marker=dict(size=3, opacity=0.6)), row=2, col=1)

    if breakthrough_points:
        breakthrough_x, breakthrough_y = zip(*breakthrough_points)
        fig.add_trace(go.Scatter(x=breakthrough_x, y=breakthrough_y, mode="markers", name="çªç ´ç‚¹", marker=dict(size=10, color="red", symbol="star", line=dict(width=2, color="black"))), row=2, col=1)

    # 4. ä¼˜åŒ–æ•ˆç‡åˆ†æ
    efficiency_scores = calculate_optimization_efficiency(objective_values)
    fig.add_trace(
        go.Scatter(x=trial_numbers[1:], y=efficiency_scores, mode="lines+markers", name="ä¼˜åŒ–æ•ˆç‡", line=dict(color="purple", width=2), marker=dict(size=4)), row=2, col=2  # ä»ç¬¬äºŒä¸ªtrialå¼€å§‹
    )

    fig.update_layout(title="ä¼˜åŒ–è¿‡ç¨‹æ·±åº¦æ´å¯Ÿåˆ†æ", height=800, width=1200, showlegend=True)

    fig.write_html(os.path.join(vis_dir, "enhanced_optimization_insight.html"))


def analyze_exploration_exploitation(trials):
    """åˆ†ææ¢ç´¢ä¸åˆ©ç”¨çš„å¹³è¡¡"""
    exploration_scores = []
    exploitation_scores = []

    for i, trial in enumerate(trials):
        if i == 0:
            exploration_scores.append(1.0)
            exploitation_scores.append(0.0)
            continue

        # è®¡ç®—å½“å‰å‚æ•°é…ç½®ä¸å†å²æœ€ä½³é…ç½®çš„å·®å¼‚ï¼ˆæ¢ç´¢åº¦ï¼‰
        best_so_far = max(trials[:i], key=lambda x: x.values[0] if x.values else -np.inf)

        param_diff = 0
        param_count = 0
        for param_name in trial.params:
            if param_name in best_so_far.params:
                param_diff += abs(trial.params[param_name] - best_so_far.params[param_name])
                param_count += 1

        if param_count > 0:
            exploration = param_diff / param_count
            exploration_scores.append(min(exploration / 5.0, 1.0))  # å½’ä¸€åŒ–
        else:
            exploration_scores.append(0.0)

        # è®¡ç®—åˆ©ç”¨åº¦ï¼ˆåŸºäºä¸å†å²æœ€ä½³çš„ç›¸ä¼¼æ€§ï¼‰
        exploitation_scores.append(1.0 - exploration_scores[-1])

    return exploration_scores, exploitation_scores


def identify_breakthrough_points(objective_values, trial_numbers, threshold=0.05):
    """è¯†åˆ«æ€§èƒ½çªç ´ç‚¹"""
    breakthrough_points = []

    if len(objective_values) < 3:
        return breakthrough_points

    # è®¡ç®—ç§»åŠ¨å¹³å‡
    window = min(5, len(objective_values) // 3)
    moving_avg = pd.Series(objective_values).rolling(window=window, center=True).mean()

    # è¯†åˆ«æ˜¾è‘—æå‡ç‚¹
    for i in range(window, len(objective_values) - window):
        if i > 0:
            improvement = (moving_avg.iloc[i] - moving_avg.iloc[i - 1]) / abs(moving_avg.iloc[i - 1])
            if improvement > threshold:
                breakthrough_points.append((trial_numbers[i], objective_values[i]))

    return breakthrough_points


def calculate_optimization_efficiency(objective_values):
    """è®¡ç®—ä¼˜åŒ–æ•ˆç‡"""
    efficiency_scores = []

    for i in range(1, len(objective_values)):
        # è®¡ç®—æ”¹è¿›ç‡
        if i == 1:
            improvement = 1.0 if objective_values[i] > objective_values[i - 1] else 0.0
        else:
            # åŸºäºæœ€è¿‘å‡ æ¬¡è¯•éªŒçš„å¹³å‡æ”¹è¿›
            recent_window = min(5, i)
            recent_best = max(objective_values[max(0, i - recent_window) : i])
            current_value = objective_values[i]

            if recent_best > 0:
                improvement = max(0, (current_value - recent_best) / recent_best)
            else:
                improvement = 1.0 if current_value > recent_best else 0.0

        efficiency_scores.append(improvement)

    return efficiency_scores


def create_optimization_guidance_report(study, traffic_files, save_dir):
    """åˆ›å»ºå‚æ•°ä¼˜åŒ–æŒ‡å¯¼æŠ¥å‘Š"""
    complete_trials = [t for t in study.trials if t.state.name == "COMPLETE"]

    if len(complete_trials) < 10:
        return

    # åˆ†ææ¯ä¸ªå‚æ•°çš„ä¼˜åŒ–ç­–ç•¥
    param_names = list(complete_trials[0].params.keys()) if complete_trials else []
    optimization_insights = {}

    for param in param_names:
        insights = analyze_parameter_optimization_strategy(complete_trials, param)
        optimization_insights[param] = insights

    # ç”Ÿæˆä¼˜åŒ–æŒ‡å¯¼æ–‡æ¡£
    guidance_html = generate_optimization_guidance_html(optimization_insights, complete_trials, traffic_files)

    with open(os.path.join(save_dir, "optimization_guidance.html"), "w", encoding="utf-8") as f:
        f.write(guidance_html)


def analyze_parameter_optimization_strategy(trials, param_name):
    """åˆ†æå•ä¸ªå‚æ•°çš„ä¼˜åŒ–ç­–ç•¥"""
    from scipy import stats

    param_values = [t.params[param_name] for t in trials]
    performance_values = [t.values[0] for t in trials]

    # è®¡ç®—ç›¸å…³æ€§
    correlation, p_value = stats.pearsonr(param_values, performance_values)

    # æ‰¾å‡ºæœ€ä½³å€¼èŒƒå›´
    top_trials = sorted(trials, key=lambda x: x.values[0], reverse=True)[: len(trials) // 4]
    best_param_values = [t.params[param_name] for t in top_trials]

    optimal_range = (min(best_param_values), max(best_param_values))
    optimal_mean = np.mean(best_param_values)

    # åˆ†æå‚æ•°æ•æ„Ÿæ€§
    sensitivity = analyze_parameter_sensitivity(param_values, performance_values)

    # ç”Ÿæˆä¼˜åŒ–å»ºè®®
    recommendations = generate_parameter_recommendations(param_name, correlation, optimal_range, optimal_mean, sensitivity)

    return {"correlation": correlation, "p_value": p_value, "optimal_range": optimal_range, "optimal_mean": optimal_mean, "sensitivity": sensitivity, "recommendations": recommendations}


def analyze_parameter_sensitivity(param_values, performance_values):
    """åˆ†æå‚æ•°æ•æ„Ÿæ€§"""
    if len(param_values) < 5:
        return "æ•°æ®ä¸è¶³"

    # è®¡ç®—å‚æ•°å˜åŒ–å¯¹æ€§èƒ½çš„å½±å“
    param_changes = np.diff(param_values)
    perf_changes = np.diff(performance_values)

    # é¿å…é™¤é›¶é”™è¯¯
    non_zero_changes = param_changes[param_changes != 0]
    corresponding_perf_changes = perf_changes[param_changes != 0]

    if len(non_zero_changes) == 0:
        return "ä½æ•æ„Ÿæ€§"

    # è®¡ç®—æ•æ„Ÿæ€§åˆ†æ•°
    sensitivity_scores = np.abs(corresponding_perf_changes / non_zero_changes)
    avg_sensitivity = np.mean(sensitivity_scores)

    if avg_sensitivity > 1.0:
        return "é«˜æ•æ„Ÿæ€§"
    elif avg_sensitivity > 0.5:
        return "ä¸­ç­‰æ•æ„Ÿæ€§"
    else:
        return "ä½æ•æ„Ÿæ€§"


def generate_parameter_recommendations(param_name, correlation, optimal_range, optimal_mean, sensitivity):
    """ç”Ÿæˆå‚æ•°ä¼˜åŒ–å»ºè®®"""
    recommendations = []

    # åŸºäºç›¸å…³æ€§çš„å»ºè®®
    if abs(correlation) > 0.7:
        if correlation > 0:
            recommendations.append(f"ğŸ“ˆ {param_name} ä¸æ€§èƒ½å‘ˆå¼ºæ­£ç›¸å…³ï¼Œå»ºè®®é€‚å½“å¢å¤§æ­¤å‚æ•°")
        else:
            recommendations.append(f"ğŸ“‰ {param_name} ä¸æ€§èƒ½å‘ˆå¼ºè´Ÿç›¸å…³ï¼Œå»ºè®®é€‚å½“å‡å°æ­¤å‚æ•°")
    elif abs(correlation) > 0.3:
        recommendations.append(f"ğŸ“Š {param_name} ä¸æ€§èƒ½å­˜åœ¨ä¸­ç­‰ç›¸å…³æ€§ï¼Œéœ€è¦ç»“åˆå…¶ä»–å‚æ•°ç»¼åˆè€ƒè™‘")
    else:
        recommendations.append(f"ğŸ”„ {param_name} ä¸æ€§èƒ½ç›¸å…³æ€§è¾ƒå¼±ï¼Œå¯èƒ½å­˜åœ¨éçº¿æ€§å…³ç³»æˆ–å‚æ•°å†—ä½™")

    # åŸºäºæœ€ä¼˜èŒƒå›´çš„å»ºè®®
    range_size = optimal_range[1] - optimal_range[0]
    if range_size <= 2:
        recommendations.append(f"ğŸ¯ æœ€ä½³å€¼é›†ä¸­åœ¨ {optimal_range[0]}-{optimal_range[1]} èŒƒå›´å†…ï¼Œå»ºè®®ç²¾ç¡®è°ƒä¼˜")
    else:
        recommendations.append(f"ğŸ” æœ€ä½³å€¼åˆ†å¸ƒåœ¨ {optimal_range[0]}-{optimal_range[1]} èŒƒå›´å†…ï¼Œå»ºè®®åœ¨æ­¤èŒƒå›´å†…æ¢ç´¢")

    # åŸºäºæ•æ„Ÿæ€§çš„å»ºè®®
    if sensitivity == "é«˜æ•æ„Ÿæ€§":
        recommendations.append(f"âš ï¸ {param_name} é«˜åº¦æ•æ„Ÿï¼Œå°å¹…è°ƒæ•´å³å¯æ˜¾è‘—å½±å“æ€§èƒ½ï¼Œéœ€è¦ç²¾ç»†è°ƒä¼˜")
    elif sensitivity == "ä¸­ç­‰æ•æ„Ÿæ€§":
        recommendations.append(f"âš–ï¸ {param_name} ä¸­ç­‰æ•æ„Ÿï¼Œå¯ä»¥é€‚åº¦è°ƒæ•´æ¥ä¼˜åŒ–æ€§èƒ½")
    else:
        recommendations.append(f"ğŸ”§ {param_name} æ•æ„Ÿæ€§è¾ƒä½ï¼Œå¯ä»¥å¤§å¹…è°ƒæ•´æˆ–è€ƒè™‘å›ºå®šæ­¤å‚æ•°")

    # æ¨èèµ·å§‹å€¼
    recommendations.append(f"ğŸ’¡ å»ºè®®èµ·å§‹å€¼: {int(optimal_mean):.1f} (åŸºäºæœ€ä½³è¯•éªŒçš„å¹³å‡å€¼)")

    return recommendations


def generate_optimization_guidance_html(optimization_insights, trials, traffic_files):
    """ç”Ÿæˆä¼˜åŒ–æŒ‡å¯¼HTMLæ–‡æ¡£"""

    # è·å–æœ€ä½³è¯•éªŒ
    best_trial = max(trials, key=lambda x: x.values[0])

    # è®¡ç®—æ•´ä½“ç»Ÿè®¡ä¿¡æ¯
    performance_values = [t.values[0] for t in trials]
    performance_improvement = (max(performance_values) - min(performance_values)) / min(performance_values) * 100

    # æ‰¾å‡ºæœ€é‡è¦çš„å‚æ•°
    param_importance = {param: abs(insights.get("correlation", 0)) for param, insights in optimization_insights.items()}
    most_important_param = max(param_importance.keys(), key=lambda x: param_importance[x])

    html_content = f"""
    <!DOCTYPE html>
    <html>
    <head>
        <title>å‚æ•°ä¼˜åŒ–ç­–ç•¥æŒ‡å¯¼</title>
        <meta charset="utf-8">
        <style>
            body {{ 
                font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Arial, sans-serif; 
                margin: 40px; 
                line-height: 1.6;
                color: #333;
            }}
            .header {{ 
                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                color: white;
                padding: 30px; 
                border-radius: 10px;
                margin-bottom: 30px;
            }}
            .section {{ 
                margin: 25px 0; 
                padding: 20px;
                background: #f8f9fa;
                border-radius: 8px;
                border-left: 4px solid #007bff;
            }}
            .param-analysis {{
                background: white;
                padding: 20px;
                margin: 15px 0;
                border-radius: 8px;
                box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            }}
            .metric {{ 
                display: inline-block; 
                margin: 10px 15px; 
                padding: 15px 20px; 
                background: white;
                border-radius: 8px; 
                box-shadow: 0 2px 4px rgba(0,0,0,0.1);
                min-width: 200px;
            }}
            .recommendations {{
                background: #e8f5e8;
                padding: 15px;
                border-radius: 8px;
                margin-top: 15px;
            }}
            .recommendations ul {{
                margin: 10px 0;
                padding-left: 0;
                list-style: none;
            }}
            .recommendations li {{
                margin: 8px 0;
                padding: 8px 12px;
                background: white;
                border-radius: 5px;
                border-left: 3px solid #28a745;
            }}
        </style>
    </head>
    <body>
        <div class="header">
            <h1>ğŸ¯ å‚æ•°ä¼˜åŒ–ç­–ç•¥æŒ‡å¯¼æŠ¥å‘Š</h1>
            <p>åŸºäº {len(trials)} æ¬¡è¯•éªŒçš„æ·±åº¦åˆ†æ | ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
            <p>æ€§èƒ½æå‡: <strong>{performance_improvement:.1f}%</strong> | æœ€ä½³æ€§èƒ½: <strong>{best_trial.values[0]:.2f}</strong></p>
        </div>
        
        <div class="section">
            <h2>ğŸ† å…³é”®å‘ç°</h2>
            <ul>
                <li><strong>æœ€å…³é”®å‚æ•°</strong>: {most_important_param}</li>
                <li><strong>ä¼˜åŒ–æ½œåŠ›</strong>: {performance_improvement:.1f}% æ€§èƒ½æå‡ç©ºé—´</li>
                <li><strong>ç¨³å®šæ€§</strong>: {'é«˜' if performance_improvement < 50 else 'ä¸­ç­‰'}</li>
            </ul>
        </div>
        
        <div class="section">
            <h2>ğŸ“‹ è¯¦ç»†å‚æ•°åˆ†æ</h2>
    """

    # ä¸ºæ¯ä¸ªå‚æ•°ç”Ÿæˆè¯¦ç»†åˆ†æ
    for param_name, insights in optimization_insights.items():
        correlation = insights.get("correlation", 0)
        optimal_range = insights.get("optimal_range", (0, 0))
        optimal_mean = insights.get("optimal_mean", 0)
        sensitivity = insights.get("sensitivity", "æœªçŸ¥")
        recommendations = insights.get("recommendations", [])

        html_content += f"""
            <div class="param-analysis">
                <h3>ğŸ”§ {param_name}</h3>
                <p><strong>ç›¸å…³æ€§</strong>: {correlation:.3f} | <strong>æœ€ä¼˜èŒƒå›´</strong>: {optimal_range[0]:.0f}-{optimal_range[1]:.0f} | <strong>æ¨èå€¼</strong>: {int(optimal_mean)}</p>
                
                <div class="recommendations">
                    <h4>ğŸ¯ ä¼˜åŒ–å»ºè®®:</h4>
                    <ul>
        """

        for rec in recommendations:
            html_content += f"<li>{rec}</li>"

        html_content += """
                    </ul>
                </div>
            </div>
        """

    html_content += """
        </div>
    </body>
    </html>
    """

    return html_content


# ============= ä¿®æ”¹ä¸»å‡½æ•°ä¸­çš„è°ƒç”¨ =============
def enhanced_create_visualization_plots(study, traffic_files, traffic_weights, save_dir):
    """å¢å¼ºç‰ˆå¯è§†åŒ–å›¾è¡¨åˆ›å»ºå‡½æ•° - åœ¨åŸæœ‰åŸºç¡€ä¸Šæ·»åŠ æ–°åŠŸèƒ½"""
    print("ç”Ÿæˆå¢å¼ºç‰ˆå¯è§†åŒ–å›¾è¡¨...")

    # åˆ›å»ºå¯è§†åŒ–ç›®å½•
    vis_dir = os.path.join(save_dir, "visualizations")
    os.makedirs(vis_dir, exist_ok=True)

    # è·å–å®Œæˆçš„trials
    complete_trials = [t for t in study.trials if t.state.name == "COMPLETE"]
    if not complete_trials:
        print("æ²¡æœ‰å®Œæˆçš„trialsï¼Œè·³è¿‡å¯è§†åŒ–")
        return

    # ========== ä¿ç•™æ‰€æœ‰åŸæœ‰çš„å¯è§†åŒ–å‡½æ•° ==========
    create_optimization_history(complete_trials, vis_dir)
    create_parameter_importance(study, vis_dir)
    create_pareto_front(complete_trials, traffic_files, vis_dir)
    create_parameter_correlation(complete_trials, vis_dir)
    create_multi_traffic_comparison(complete_trials, traffic_files, traffic_weights, vis_dir)
    create_parameter_distribution(complete_trials, vis_dir)
    create_convergence_plot(complete_trials, vis_dir)
    create_3d_parameter_space(complete_trials, vis_dir)
    create_single_parameter_line_plots(complete_trials, save_dir=vis_dir)

    # ========== æ–°å¢å¢å¼ºç‰ˆå¯è§†åŒ–å‡½æ•° ==========
    create_parameter_impact_plot(complete_trials, traffic_files, vis_dir)
    create_enhanced_optimization_insight(study, vis_dir)
    create_optimization_guidance_report(study, traffic_files, vis_dir)
    # æ–°å¢ 2D å‚æ•°Ã—å¸¦å®½çƒ­åŠ›å›¾
    create_2d_param_bw_heatmaps(
        complete_trials,
        metric_key="Total_sum_BW_weighted_mean",  # ä½ ä¹Ÿå¯ä»¥ç”¨å•ä¸ª traffic çš„ key
        # æ‰‹åŠ¨æŒ‡å®šæ„Ÿå…´è¶£çš„å‚æ•°å¯¹ï¼›ç•™ç©ºåˆ™æ‰€æœ‰ä¸¤ä¸¤ç»„åˆéƒ½ä¼šç”»
        param_pairs=[
            ("TL_Etag_T2_UE_MAX", "TL_Etag_T1_UE_MAX"),
            ("TU_Etag_T2_UE_MAX", "TU_Etag_T1_UE_MAX"),
            ("RB_IN_FIFO_DEPTH", "EQ_IN_FIFO_DEPTH"),
        ],
        save_dir=vis_dir,
    )

    print(f"å¢å¼ºç‰ˆå¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜åˆ°: {vis_dir}")


def create_single_parameter_line_plots(trials, metric_key="Total_sum_BW_weighted_mean", save_dir="."):
    """ä¸ºæ¯ä¸ªå‚æ•°ç»˜åˆ¶ä¸€ç»´æ€§èƒ½æ›²çº¿"""
    import pandas as pd

    if not trials:
        return

    rows = []
    for t in trials:
        if t.state.name != "COMPLETE" or t.values is None:
            continue
        row = {k: v for k, v in t.params.items()}
        row[metric_key] = t.user_attrs.get(metric_key, t.values[0])
        rows.append(row)

    df = pd.DataFrame(rows)
    if df.empty:
        return

    os.makedirs(save_dir, exist_ok=True)

    for param in [c for c in df.columns if c != metric_key]:
        agg = df.groupby(param)[metric_key].mean().reset_index().sort_values(param)
        fig = go.Figure(data=go.Scatter(x=agg[param], y=agg[metric_key], mode="lines+markers"))
        fig.update_layout(title=f"{param} å¯¹æ€§èƒ½å½±å“", xaxis_title=param, yaxis_title=metric_key, height=400)
        fig.write_html(os.path.join(save_dir, f"{param}_line.html"))


def create_2d_param_bw_heatmaps(trials, metric_key="Total_sum_BW_weighted_mean", param_pairs=None, aggfunc="mean", save_dir="."):
    """
    ç»˜åˆ¶æ‰€æœ‰æŒ‡å®šå‚æ•°å¯¹çš„ 2D çƒ­åŠ›å›¾
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    â€¢ trials        : List[optuna.Trial]ï¼Œåªä¼  COMPLETE çš„å°±è¡Œ
    â€¢ metric_key    : ä½œä¸ºè‰²å€¼çš„æŒ‡æ ‡ï¼›é»˜è®¤ç”¨åŠ æƒæ•´ä½“å¸¦å®½
    â€¢ param_pairs   : [('paramA','paramB'), ...]ï¼›ä¸ºç©ºæ—¶è‡ªåŠ¨å–æ‰€æœ‰ä¸¤ä¸¤ç»„åˆ
    â€¢ aggfunc       : 'mean' | 'max' | 'min' ç­‰ï¼Œé€è§†è¡¨èšåˆæ–¹å¼
    â€¢ save_dir      : html/png è¾“å‡ºç›®å½•
    """
    import plotly.graph_objects as go
    import pandas as pd, numpy as np, os, itertools, seaborn as sns, matplotlib.pyplot as plt

    # ------- æ•´ç† DataFrame -------
    rows = []
    for t in trials:
        if t.state.name != "COMPLETE" or t.values is None:
            continue
        row = {k: v for k, v in t.params.items()}
        row[metric_key] = t.user_attrs.get(metric_key, t.values[0])
        rows.append(row)
    df = pd.DataFrame(rows)
    if df.empty:
        print("æ²¡æœ‰å¯ç”¨ Trial æ•°æ®ï¼Œè·³è¿‡ 2D çƒ­åŠ›å›¾ç»˜åˆ¶")
        return

    # ------- è‡ªåŠ¨ç»„åˆå‚æ•°å¯¹ -------
    if not param_pairs:
        cols = list(trials[0].params.keys())
        param_pairs = list(itertools.combinations(cols, 2))

    os.makedirs(save_dir, exist_ok=True)

    # ------- é€å¯¹ç»˜åˆ¶ -------
    for x, y in param_pairs:
        pivot = df.pivot_table(index=y, columns=x, values=metric_key, aggfunc=aggfunc)
        title = f"{y} vs {x} â€” {metric_key}"

        # â€”â€”â€” æ–¹æ³• Aï¼šPlotlyï¼ˆäº¤äº’å¼ï¼Œé»˜è®¤è¾“å‡º HTMLï¼‰ â€”â€”â€”
        fig = go.Figure(data=go.Heatmap(z=pivot.values, x=pivot.columns, y=pivot.index, colorscale="Viridis", colorbar=dict(title=metric_key)))
        fig.update_layout(title=title, xaxis_title=x, yaxis_title=y, height=600, width=750)
        fig.write_html(os.path.join(save_dir, f"{y}_vs_{x}.html"))

        # â€”â€”â€” æ–¹æ³• Bï¼šSeabornï¼ˆé™æ€ PNGï¼Œå¯é€‰ï¼‰ â€”â€”â€”
        plt.figure(figsize=(10, 8))
        ax = sns.heatmap(pivot, cmap="YlGnBu", annot=True, fmt=".1f", linewidths=0.5, linecolor="white")
        ax.invert_yaxis()
        plt.title(title, fontsize=14)
        plt.tight_layout()
        plt.savefig(os.path.join(save_dir, f"{y}_vs_{x}.png"), dpi=200)
        plt.close()


def create_optimization_history(trials, save_dir):
    """åˆ›å»ºä¼˜åŒ–å†å²å›¾"""
    fig = make_subplots(
        rows=2,
        cols=2,
        subplot_titles=("ä¼˜åŒ–å†å²", "æœ€ä½³å€¼å†å²", "TrialçŠ¶æ€åˆ†å¸ƒ", "ç›®æ ‡å‡½æ•°åˆ†å¸ƒ"),
        specs=[[{"secondary_y": True}, {"secondary_y": False}], [{"type": "pie"}, {"type": "histogram"}]],
    )

    # ä¼˜åŒ–å†å²ï¼ˆè¿‡æ»¤æ‰valuesä¸ºNoneçš„trialï¼‰
    valid_trials = [t for t in trials if t.values is not None]
    trial_numbers = [t.number for t in valid_trials]
    objective_values = [t.values[0] for t in valid_trials]
    best_values = []
    best_so_far = float("-inf")
    for val in objective_values:
        if val > best_so_far:
            best_so_far = val
        best_values.append(best_so_far)

    fig.add_trace(go.Scatter(x=trial_numbers, y=objective_values, mode="markers", name="Trialå€¼", opacity=0.6, marker=dict(color="lightblue")), row=1, col=1)
    fig.add_trace(go.Scatter(x=trial_numbers, y=best_values, mode="lines", name="æœ€ä½³å€¼", line=dict(color="red", width=2)), row=1, col=1, secondary_y=False)

    # æœ€ä½³å€¼å†å²ï¼ˆæ”¾å¤§ï¼‰
    fig.add_trace(go.Scatter(x=trial_numbers, y=best_values, mode="lines+markers", name="æœ€ä½³å€¼å†å²", line=dict(color="green")), row=1, col=2)

    # TrialçŠ¶æ€åˆ†å¸ƒ
    states = [t.state.name if hasattr(t.state, "name") else str(t.state) for t in trials]
    state_counts = pd.Series(states).value_counts()
    fig.add_trace(go.Pie(labels=state_counts.index, values=state_counts.values, name="çŠ¶æ€"), row=2, col=1)

    # ç›®æ ‡å‡½æ•°åˆ†å¸ƒ
    fig.add_trace(go.Histogram(x=objective_values, name="ç›®æ ‡å‡½æ•°åˆ†å¸ƒ", nbinsx=30), row=2, col=2)

    fig.update_layout(height=800, title_text="ä¼˜åŒ–è¿‡ç¨‹åˆ†æ")
    fig.write_html(os.path.join(save_dir, "optimization_history.html"))


def create_parameter_importance(study, save_dir):
    """åˆ›å»ºå‚æ•°é‡è¦æ€§å›¾"""
    try:
        # é’ˆå¯¹å¤šç›®æ ‡ Study éœ€æŒ‡å®š targetï¼›é»˜è®¤ä½¿ç”¨ç¬¬ 1 ä¸ªæŒ‡æ ‡
        if len(study.directions) > 1:
            importance = optuna.importance.get_param_importances(study, target=lambda t: t.values[0] if t.values else 0)
        else:
            importance = optuna.importance.get_param_importances(study)

        params = list(importance.keys())
        values = list(importance.values())

        fig = go.Figure(data=[go.Bar(x=values, y=params, orientation="h", marker=dict(color=values, colorscale="Viridis"))])

        fig.update_layout(title="å‚æ•°é‡è¦æ€§åˆ†æ", xaxis_title="é‡è¦æ€§åˆ†æ•°", yaxis_title="å‚æ•°", height=600)

        fig.write_html(os.path.join(save_dir, "parameter_importance.html"))
    except Exception as e:
        print("å‚æ•°é‡è¦æ€§åˆ†æå¤±è´¥ï¼Œè¯¦ç»†é”™è¯¯ä¿¡æ¯ï¼š")
        traceback.print_exc()


def create_pareto_front(trials, traffic_files, save_dir):
    """åˆ›å»ºParetoå‰æ²¿å›¾"""
    if len(traffic_files) < 2:
        return

    # æå–ä¸¤ä¸ªä¸»è¦æŒ‡æ ‡
    x_vals = []
    y_vals = []
    colors = []
    texts = []

    traffic1_name = traffic_files[0][:-4]
    traffic2_name = traffic_files[1][:-4]

    for trial in trials:
        if trial.values is not None:
            x_key = f"Total_sum_BW_mean_{traffic1_name}"
            y_key = f"Total_sum_BW_mean_{traffic2_name}"

            if x_key in trial.user_attrs and y_key in trial.user_attrs:
                x_vals.append(trial.user_attrs[x_key])
                y_vals.append(trial.user_attrs[y_key])
                colors.append(trial.user_attrs.get("Total_sum_BW_weighted_mean", trial.values[0]))
                texts.append(f"Trial {trial.number}<br>" f"{traffic1_name}: {x_vals[-1]:.2f}<br>" f"{traffic2_name}: {y_vals[-1]:.2f}")

    if x_vals and y_vals:
        fig = go.Figure(
            data=go.Scatter(
                x=x_vals,
                y=y_vals,
                mode="markers",
                marker=dict(size=8, color=colors, colorscale="Viridis", colorbar=dict(title="åŠ æƒå¾—åˆ†"), line=dict(width=1, color="black")),
                text=texts,
                hovertemplate="%{text}<extra></extra>",
            )
        )

        fig.update_layout(title=f"Paretoå‰æ²¿: {traffic1_name} vs {traffic2_name}", xaxis_title=f"{traffic1_name} å¸¦å®½ (GB/s)", yaxis_title=f"{traffic2_name} å¸¦å®½ (GB/s)", height=600)

        fig.write_html(os.path.join(save_dir, "pareto_front.html"))


def create_parameter_correlation(trials, save_dir):
    """åˆ›å»ºå‚æ•°ç›¸å…³æ€§çƒ­åŠ›å›¾"""
    # æ„å»ºæ•°æ®çŸ©é˜µ
    data = []
    for trial in trials:
        if trial.values is not None:
            row = {}
            for param_name, param_value in trial.params.items():
                row[param_name] = param_value
            row["objective"] = trial.user_attrs.get("Total_sum_BW_weighted_mean", trial.values[0])
            data.append(row)

    if data:
        df = pd.DataFrame(data)
        corr_matrix = df.corr()

        fig = go.Figure(
            data=go.Heatmap(
                z=corr_matrix.values,
                x=corr_matrix.columns,
                y=corr_matrix.columns,
                colorscale="RdBu",
                zmid=0,
                text=np.round(corr_matrix.values, 2),
                texttemplate="%{text}",
                textfont={"size": 10},
                hoverongaps=False,
            )
        )

        fig.update_layout(title="å‚æ•°ç›¸å…³æ€§çŸ©é˜µ", height=600, width=800)

        fig.write_html(os.path.join(save_dir, "parameter_correlation.html"))


def create_multi_traffic_comparison(trials, traffic_files, traffic_weights, save_dir):
    """åˆ›å»ºå¤šTrafficæ€§èƒ½å¯¹æ¯”å›¾"""
    # å‡†å¤‡æ•°æ®
    traffic_data = {f"{tf[:-4]}": [] for tf in traffic_files}
    weighted_data = []
    trial_numbers = []

    for trial in trials:
        if trial.values is not None:
            trial_numbers.append(trial.number)
            weighted_data.append(trial.user_attrs.get("Total_sum_BW_weighted_mean", 0))

            for tf in traffic_files:
                traffic_name = tf[:-4]
                key = f"Total_sum_BW_mean_{traffic_name}"
                traffic_data[traffic_name].append(trial.user_attrs.get(key, 0))

    # åˆ›å»ºå­å›¾
    fig = make_subplots(
        rows=2,
        cols=2,
        subplot_titles=("å„Trafficæ€§èƒ½å¯¹æ¯”", "åŠ æƒå¹³å‡vsæœ€å°å€¼", "Top 10 Trialså¯¹æ¯”", "æƒé‡å½±å“åˆ†æ"),
        specs=[[{"secondary_y": False}, {"secondary_y": False}], [{"secondary_y": False}, {"type": "bar"}]],
    )

    # 1. å„Trafficæ€§èƒ½å¯¹æ¯”
    colors = px.colors.qualitative.Set1
    for i, (traffic_name, values) in enumerate(traffic_data.items()):
        fig.add_trace(go.Scatter(x=trial_numbers, y=values, mode="markers", name=traffic_name, marker=dict(color=colors[i % len(colors)])), row=1, col=1)

    # 2. åŠ æƒå¹³å‡vsæœ€å°å€¼
    min_values = [trial.user_attrs.get("Total_sum_BW_min", 0) for trial in trials if trial.values is not None]
    fig.add_trace(go.Scatter(x=weighted_data, y=min_values, mode="markers", name="åŠ æƒå¹³å‡vsæœ€å°å€¼", marker=dict(color="red")), row=1, col=2)

    # 3. Top 10 Trialså¯¹æ¯”
    top_trials = sorted(trials, key=lambda t: t.values[0] if t.values else float("-inf"), reverse=True)[:10]
    top_data = {}
    for tf in traffic_files:
        traffic_name = tf[:-4]
        key = f"Total_sum_BW_mean_{traffic_name}"
        top_data[traffic_name] = [t.user_attrs.get(key, 0) for t in top_trials]

    x_pos = list(range(len(top_trials)))
    for i, (traffic_name, values) in enumerate(top_data.items()):
        fig.add_trace(go.Bar(x=x_pos, y=values, name=f"Top10-{traffic_name}", marker=dict(color=colors[i % len(colors)]), opacity=0.7), row=2, col=1)

    # 4. æƒé‡å½±å“åˆ†æ
    weight_labels = [f"{tf[:-4]}<br>({w:.1%})" for tf, w in zip(traffic_files, traffic_weights)]
    fig.add_trace(go.Bar(x=weight_labels, y=traffic_weights, name="Trafficæƒé‡", marker=dict(color="lightgreen")), row=2, col=2)

    fig.update_layout(height=1000, title_text="å¤šTrafficæ€§èƒ½åˆ†æ")
    fig.write_html(os.path.join(save_dir, "multi_traffic_comparison.html"))


def create_parameter_distribution(trials, save_dir):
    """åˆ›å»ºå‚æ•°åˆ†å¸ƒå›¾"""
    # è·å–æ‰€æœ‰å‚æ•°
    param_names = list(trials[0].params.keys()) if trials else []
    if not param_names:
        return

    # åˆ›å»ºå­å›¾
    n_params = len(param_names)
    cols = 3
    rows = (n_params + cols - 1) // cols

    fig = make_subplots(rows=rows, cols=cols, subplot_titles=param_names, specs=[[{"type": "histogram"}] * cols for _ in range(rows)])

    for i, param_name in enumerate(param_names):
        row = i // cols + 1
        col = i % cols + 1

        values = [trial.params[param_name] for trial in trials if trial.values is not None]

        fig.add_trace(go.Histogram(x=values, name=param_name, nbinsx=20), row=row, col=col)

    fig.update_layout(height=300 * rows, title_text="å‚æ•°åˆ†å¸ƒåˆ†æ")
    fig.write_html(os.path.join(save_dir, "parameter_distribution.html"))


def create_convergence_plot(trials, save_dir):
    """åˆ›å»ºæ”¶æ•›å›¾"""
    if len(trials) < 10:
        return

    # è®¡ç®—ç§»åŠ¨å¹³å‡
    window_sizes = [10, 20, 50]
    trial_numbers = [t.number for t in trials]
    objective_values = [t.values[0] for t in trials]

    fig = go.Figure()

    # åŸå§‹æ•°æ®
    fig.add_trace(go.Scatter(x=trial_numbers, y=objective_values, mode="markers", name="åŸå§‹å€¼", marker=dict(color="lightblue", size=4, opacity=0.6)))

    # ç§»åŠ¨å¹³å‡
    colors = ["red", "green", "purple"]
    for i, window in enumerate(window_sizes):
        if len(objective_values) >= window:
            moving_avg = pd.Series(objective_values).rolling(window=window, center=True).mean()
            fig.add_trace(go.Scatter(x=trial_numbers, y=moving_avg, mode="lines", name=f"{window}ç‚¹ç§»åŠ¨å¹³å‡", line=dict(color=colors[i], width=2)))

    # æœ€ä½³å€¼çº¿
    best_values = []
    best_so_far = float("-inf")
    for val in objective_values:
        if val > best_so_far:
            best_so_far = val
        best_values.append(best_so_far)

    fig.add_trace(go.Scatter(x=trial_numbers, y=best_values, mode="lines", name="æœ€ä½³å€¼", line=dict(color="orange", width=3, dash="dash")))

    fig.update_layout(title="ä¼˜åŒ–æ”¶æ•›åˆ†æ", xaxis_title="Trialç¼–å·", yaxis_title="ç›®æ ‡å‡½æ•°å€¼", height=600)

    fig.write_html(os.path.join(save_dir, "convergence_analysis.html"))


def create_3d_parameter_space(trials, save_dir):
    """åˆ›å»º3Då‚æ•°ç©ºé—´å›¾"""
    if len(trials) < 20:
        return

    # é€‰æ‹©æœ€é‡è¦çš„3ä¸ªå‚æ•°ï¼ˆåŸºäºæ–¹å·®ï¼‰
    param_data = {}
    for trial in trials:
        if trial.values is not None:
            for param_name, param_value in trial.params.items():
                if param_name not in param_data:
                    param_data[param_name] = []
                param_data[param_name].append(param_value)

    # è®¡ç®—æ–¹å·®é€‰æ‹©å‚æ•°
    param_vars = {name: np.var(values) for name, values in param_data.items()}
    top_params = sorted(param_vars.items(), key=lambda x: x[1], reverse=True)[:3]

    if len(top_params) >= 3:
        param_names = [p[0] for p in top_params]

        x_vals = [trial.params[param_names[0]] for trial in trials if trial.values is not None]
        y_vals = [trial.params[param_names[1]] for trial in trials if trial.values is not None]
        z_vals = [trial.params[param_names[2]] for trial in trials if trial.values is not None]
        colors = [t.user_attrs.get("Total_sum_BW_weighted_mean", t.values[0]) for t in trials if t.values is not None]

        fig = go.Figure(
            data=[
                go.Scatter3d(
                    x=x_vals,
                    y=y_vals,
                    z=z_vals,
                    mode="markers",
                    marker=dict(size=5, color=colors, colorscale="Viridis", colorbar=dict(title="ç›®æ ‡å‡½æ•°å€¼"), line=dict(width=0.5, color="black")),
                    text=[f"Trial {t.number}: {t.values}" for t in trials if t.values is not None],
                    hovertemplate="%{text}<extra></extra>",
                )
            ]
        )

        fig.update_layout(title="3Då‚æ•°ç©ºé—´æ¢ç´¢", scene=dict(xaxis_title=param_names[0], yaxis_title=param_names[1], zaxis_title=param_names[2]), height=700)

        fig.write_html(os.path.join(save_dir, "3d_parameter_space.html"))


def save_progress_callback(study, trial):
    """å®æ—¶ä¿å­˜è¿›åº¦å’Œä¸­é—´ç»“æœ"""
    global visualization_data

    # æ›´æ–°å¯è§†åŒ–æ•°æ®
    if trial.state == TrialState.COMPLETE and trial.values is not None:
        trial_data = {"number": trial.number, "values": trial.values, "params": trial.params.copy(), "user_attrs": trial.user_attrs.copy(), "timestamp": datetime.now().isoformat()}
        visualization_data["trials"].append(trial_data)

        # ä¿å­˜è¿›åº¦æ•°æ®
        progress_data = {
            "trial_number": trial.number,
            "best_values": study.best_trials[0].values if study.best_trials else None,
            "current_values": trial.values,
            "timestamp": datetime.now().isoformat(),
        }
        visualization_data["progress"].append(progress_data)

    # æ¯10ä¸ªtrialä¿å­˜ä¸€æ¬¡ä¸­é—´ç»“æœ
    if trial.number % 10 == 0:
        try:
            # ä¿å­˜åˆ°JSONæ–‡ä»¶
            progress_file = os.path.join(output_csv.replace(".csv", "_progress.json"))
            with open(progress_file, "w", encoding="utf-8") as f:
                json.dump(visualization_data, f, indent=2, ensure_ascii=False)

            # å¦‚æœæœ‰è¶³å¤Ÿçš„æ•°æ®ï¼Œç”Ÿæˆä¸­é—´å¯è§†åŒ–
            if len(visualization_data["trials"]) >= 20:
                create_intermediate_visualization(study)

        except Exception as e:
            print(f"ä¿å­˜è¿›åº¦æ•°æ®å¤±è´¥: {e}")


def create_intermediate_visualization(study):
    """åˆ›å»ºä¸­é—´è¿‡ç¨‹å¯è§†åŒ–"""
    try:
        vis_dir = os.path.join(os.path.dirname(output_csv), "intermediate_vis")
        os.makedirs(vis_dir, exist_ok=True)

        # åˆ›å»ºç®€åŒ–çš„å®æ—¶å›¾è¡¨
        complete_trials = [t for t in study.trials if t.state == TrialState.COMPLETE]

        if len(complete_trials) >= 10:
            # 1. å®æ—¶ä¼˜åŒ–å†å²
            trial_numbers = [t.number for t in complete_trials]
            objective_values = [t.values[0] for t in complete_trials]

            fig = go.Figure()
            fig.add_trace(go.Scatter(x=trial_numbers, y=objective_values, mode="markers+lines", name="ç›®æ ‡å‡½æ•°å€¼"))

            # æœ€ä½³å€¼çº¿
            best_values = []
            best_so_far = float("-inf")
            for val in objective_values:
                if val > best_so_far:
                    best_so_far = val
                best_values.append(best_so_far)

            fig.add_trace(go.Scatter(x=trial_numbers, y=best_values, mode="lines", name="æœ€ä½³å€¼", line=dict(color="red", width=2)))

            fig.update_layout(title=f"å®æ—¶ä¼˜åŒ–è¿›åº¦ (å·²å®Œæˆ{len(complete_trials)}ä¸ªè¯•éªŒ)", xaxis_title="Trialç¼–å·", yaxis_title="ç›®æ ‡å‡½æ•°å€¼")

            fig.write_html(os.path.join(vis_dir, "realtime_progress.html"))

            print(f"ä¸­é—´å¯è§†åŒ–å·²æ›´æ–°: {vis_dir}/realtime_progress.html")

    except Exception as e:
        print(f"åˆ›å»ºä¸­é—´å¯è§†åŒ–å¤±è´¥: {e}")


def find_optimal_parameters():
    global output_csv

    # traffic_file_path = r"../test_data/"
    traffic_file_path = r"../traffic/0617/"

    # ===== å¤šä¸ªtrafficæ–‡ä»¶é…ç½® =====
    traffic_files = [
        r"LLama2_AllReduce.txt",
        r"LLama2_AttentionFC.txt",
        r"MLP_MoE.txt",
        r"MLP.txt",
    ]

    # æ¯ä¸ªtrafficçš„æƒé‡ï¼ˆç”¨äºåŠ æƒå¹³å‡ï¼‰
    traffic_weights = [0.4, 0.2, 0.2, 0.2]  # ç¬¬ä¸€ä¸ªtrafficæƒé‡0.6ï¼Œç¬¬äºŒä¸ª0.4
    # traffic_weights = [1]  # ç¬¬ä¸€ä¸ªtrafficæƒé‡0.6ï¼Œç¬¬äºŒä¸ª0.4

    assert len(traffic_files) == len(traffic_weights), "trafficæ–‡ä»¶æ•°é‡å’Œæƒé‡æ•°é‡å¿…é¡»ä¸€è‡´"
    assert abs(sum(traffic_weights) - 1.0) < 1e-6, "æƒé‡æ€»å’Œå¿…é¡»ç­‰äº1"

    config_path = r"../config/topologies/topo_5x4.yaml"
    config = CrossRingConfig(config_path)

    # topo_type = "3x3"
    topo_type = "5x4"
    config.TOPO_TYPE = topo_type

    model_type = "REQ_RSP"
    results_file_name = f"2260E_ETag_multi_traffic_{datetime.now().strftime('%m%d_%H%M')}"
    result_root_save_path = f"../Result/CrossRing/{model_type}/FOP/{results_file_name}/"
    os.makedirs(result_root_save_path, exist_ok=True)
    output_csv = os.path.join(r"../Result/Params_csv/", f"{results_file_name}.csv")
    os.makedirs(os.path.dirname(output_csv), exist_ok=True)

    # å‚æ•°èŒƒå›´
    param1_start, param1_end = 2, 16
    param2_start, param2_end = 2, 16
    param3_start, param3_end = 2, 16
    param4_start, param4_end = 4, 20
    param5_start, param5_end = 2, 16
    param6_start, param6_end = 2, 16
    param7_start, param7_end = 2, 16
    param8_start, param8_end = 4, 20
    param9_start, param9_end = 0, 1

    def _run_one_traffic(traffic_file, param1, param2, param3, param4, param5, param6, param7, param8, param9):
        """è¿è¡Œå•ä¸ªtrafficæ–‡ä»¶çš„ä»¿çœŸ"""
        tot_bw_list = []
        for rpt in range(N_REPEATS):
            cfg = CrossRingConfig(config_path)
            cfg.TOPO_TYPE = topo_type

            sim = REQ_RSP_model(
                model_type=model_type,
                config=cfg,
                topo_type=topo_type,
                verbose=0,
            )

            sim.setup_traffic_scheduler(
                traffic_file_path=traffic_file_path,
                traffic_chains=traffic_file,
            )

            sim.setup_result_analysis(
                result_save_path=result_root_save_path,
            )

            # --- å›ºå®šå¹³å°å‚æ•° ------------------------------
            if topo_type == "3x3":
                sim.config.BURST = 2
                sim.config.NUM_IP = 4
                sim.config.NUM_DDR = 8
                sim.config.NUM_L2M = 4
                sim.config.NUM_GDMA = 4
                sim.config.NUM_SDMA = 4
                sim.config.NUM_RN = 4
                sim.config.NUM_SN = 8
                sim.config.RN_R_TRACKER_OSTD = 128
                sim.config.RN_W_TRACKER_OSTD = 32
                sim.config.RN_RDB_SIZE = sim.config.RN_R_TRACKER_OSTD * sim.config.BURST
                sim.config.RN_WDB_SIZE = sim.config.RN_W_TRACKER_OSTD * sim.config.BURST
                sim.config.SN_DDR_R_TRACKER_OSTD = 32
                sim.config.SN_DDR_W_TRACKER_OSTD = 16
                sim.config.SN_L2M_R_TRACKER_OSTD = 64
                sim.config.SN_L2M_W_TRACKER_OSTD = 64
                sim.config.SN_DDR_WDB_SIZE = sim.config.SN_DDR_W_TRACKER_OSTD * sim.config.BURST
                sim.config.SN_L2M_WDB_SIZE = sim.config.SN_L2M_W_TRACKER_OSTD * sim.config.BURST
                sim.config.DDR_R_LATENCY_original = 155
                sim.config.DDR_R_LATENCY_VAR_original = 25
                sim.config.DDR_W_LATENCY_original = 16
                sim.config.L2M_R_LATENCY_original = 12
                sim.config.L2M_W_LATENCY_original = 16
                sim.config.DDR_BW_LIMIT = 76.8 / 4
                sim.config.L2M_BW_LIMIT = np.inf
                sim.config.IQ_CH_FIFO_DEPTH = 8
                sim.config.EQ_CH_FIFO_DEPTH = 8
                sim.config.IQ_OUT_FIFO_DEPTH_HORIZONTAL = 8
                sim.config.IQ_OUT_FIFO_DEPTH_VERTICAL = 8
                sim.config.IQ_OUT_FIFO_DEPTH_EQ = 8
                sim.config.RB_OUT_FIFO_DEPTH = 8
                sim.config.EQ_IN_FIFO_DEPTH = 16
                sim.config.RB_IN_FIFO_DEPTH = 16
                sim.config.TL_Etag_T2_UE_MAX = 8
                sim.config.TL_Etag_T1_UE_MAX = 14
                sim.config.TR_Etag_T2_UE_MAX = 9
                sim.config.TU_Etag_T2_UE_MAX = 8
                sim.config.TU_Etag_T1_UE_MAX = 14
                sim.config.TD_Etag_T2_UE_MAX = 9
                sim.config.GDMA_RW_GAP = np.inf
                sim.config.SDMA_RW_GAP = 50
                sim.config.ETag_BOTHSIDE_UPGRADE = 0
                sim.config.CHANNEL_SPEC = {
                    "gdma": 1,
                    "sdma": 1,
                    "ddr": 4,
                    "l2m": 2,
                }
            elif topo_type in ["5x4", "4x5"]:
                sim.config.BURST = 4
                sim.config.NUM_IP = 32
                sim.config.NUM_DDR = 32
                sim.config.NUM_L2M = 32
                sim.config.NUM_GDMA = 32
                sim.config.NUM_SDMA = 32
                sim.config.NUM_RN = 32
                sim.config.NUM_SN = 32
                sim.config.RN_R_TRACKER_OSTD = 64
                sim.config.RN_W_TRACKER_OSTD = 64
                sim.config.RN_RDB_SIZE = sim.config.RN_R_TRACKER_OSTD * sim.config.BURST
                sim.config.RN_WDB_SIZE = sim.config.RN_W_TRACKER_OSTD * sim.config.BURST
                sim.config.SN_DDR_R_TRACKER_OSTD = 64
                sim.config.SN_DDR_W_TRACKER_OSTD = 64
                sim.config.SN_L2M_R_TRACKER_OSTD = 64
                sim.config.SN_L2M_W_TRACKER_OSTD = 64
                sim.config.SN_DDR_WDB_SIZE = sim.config.SN_DDR_W_TRACKER_OSTD * sim.config.BURST
                sim.config.SN_L2M_WDB_SIZE = sim.config.SN_L2M_W_TRACKER_OSTD * sim.config.BURST
                sim.config.DDR_R_LATENCY_original = 40
                sim.config.DDR_R_LATENCY_VAR_original = 0
                sim.config.DDR_W_LATENCY_original = 0
                sim.config.L2M_R_LATENCY_original = 12
                sim.config.L2M_W_LATENCY_original = 16
                sim.config.IQ_CH_FIFO_DEPTH = 10
                sim.config.EQ_CH_FIFO_DEPTH = 10
                sim.config.IQ_OUT_FIFO_DEPTH_HORIZONTAL = 8
                sim.config.IQ_OUT_FIFO_DEPTH_VERTICAL = 8
                sim.config.IQ_OUT_FIFO_DEPTH_EQ = 8
                sim.config.RB_OUT_FIFO_DEPTH = 8
                sim.config.SN_TRACKER_RELEASE_LATENCY = 40

                sim.config.TL_Etag_T2_UE_MAX = 8
                sim.config.TL_Etag_T1_UE_MAX = 15
                sim.config.TR_Etag_T2_UE_MAX = 12
                sim.config.RB_IN_FIFO_DEPTH = 16
                sim.config.TU_Etag_T2_UE_MAX = 8
                sim.config.TU_Etag_T1_UE_MAX = 15
                sim.config.TD_Etag_T2_UE_MAX = 12
                sim.config.EQ_IN_FIFO_DEPTH = 16

                sim.config.ITag_TRIGGER_Th_H = sim.config.ITag_TRIGGER_Th_V = 80
                sim.config.ITag_MAX_NUM_H = sim.config.ITag_MAX_NUM_V = 1
                sim.config.ETag_BOTHSIDE_UPGRADE = 0
                sim.config.SLICE_PER_LINK_HORIZONTAL = 8
                sim.config.SLICE_PER_LINK_VERTICAL = 8

                sim.config.GDMA_RW_GAP = np.inf
                sim.config.SDMA_RW_GAP = np.inf
                sim.config.CHANNEL_SPEC = {
                    "gdma": 2,
                    "sdma": 2,
                    "ddr": 2,
                    "l2m": 2,
                }

            # --- è¦†ç›–å¾…ä¼˜åŒ–å‚æ•° ----------------------------
            sim.config.TL_Etag_T2_UE_MAX = param1
            sim.config.TL_Etag_T1_UE_MAX = param2
            sim.config.TR_Etag_T2_UE_MAX = param3
            sim.config.RB_IN_FIFO_DEPTH = param4
            sim.config.TU_Etag_T2_UE_MAX = param5
            sim.config.TU_Etag_T1_UE_MAX = param6
            sim.config.TD_Etag_T2_UE_MAX = param7
            sim.config.EQ_IN_FIFO_DEPTH = param8
            sim.config.ETag_BOTHSIDE_UPGRADE = param9

            try:
                sim.run_simulation(max_time=10000, print_interval=10000)
                bw = sim.get_results().get("Total_sum_BW", 0)
            except Exception as e:
                print(f"[{traffic_file}][RPT {rpt}] Sim failed for params: {param1}, {param2}, {param3}, {param4}, {param5}, {param6}, {param7}, {param8}, {param9}")
                print("Exception details (full traceback):")
                traceback.print_exc()
                bw = 0
            tot_bw_list.append(bw)

        bw_mean = float(np.mean(tot_bw_list))
        bw_std = float(np.std(tot_bw_list))

        return {
            f"Total_sum_BW_mean_{traffic_file[:-4]}": bw_mean,
            f"Total_sum_BW_std_{traffic_file[:-4]}": bw_std,
        }

    def _run_one(param1, param2, param3, param4, param5, param6, param7, param8, param9):
        """è¿è¡Œæ‰€æœ‰trafficæ–‡ä»¶å¹¶ç»¼åˆç»“æœ"""
        all_results = {}
        all_bw_means = []

        for traffic_file in traffic_files:
            try:
                result = _run_one_traffic(traffic_file, param1, param2, param3, param4, param5, param6, param7, param8, param9)
                all_results.update(result)
                bw_mean = result[f"Total_sum_BW_mean_{traffic_file[:-4]}"]
                all_bw_means.append(bw_mean)
            except Exception as e:
                print(f"Error processing {traffic_file}: {e}")
                all_bw_means.append(0)
                all_results[f"Total_sum_BW_mean_{traffic_file[:-4]}"] = 0
                all_results[f"Total_sum_BW_std_{traffic_file[:-4]}"] = 0

        # è®¡ç®—åŠ æƒå¹³å‡å¸¦å®½
        weighted_bw_mean = sum(bw * weight for bw, weight in zip(all_bw_means, traffic_weights))

        # è®¡ç®—æœ€å°å¸¦å®½ï¼ˆä¿è¯æ‰€æœ‰trafficéƒ½æœ‰åˆç†æ€§èƒ½ï¼‰
        min_bw_mean = min(all_bw_means) if all_bw_means else 0

        # è®¡ç®—å¸¦å®½æ–¹å·®ï¼ˆè¡¡é‡ä¸åŒtrafficé—´çš„ä¸€è‡´æ€§ï¼‰
        bw_variance = np.var(all_bw_means) if len(all_bw_means) > 1 else 0

        # æ·»åŠ ç»¼åˆæŒ‡æ ‡
        all_results.update(
            {
                "Total_sum_BW_weighted_mean": weighted_bw_mean,
                "Total_sum_BW_min": min_bw_mean,
                "Total_sum_BW_variance": bw_variance,
                "param1": param1,
                "param2": param2,
                "param3": param3,
                "param4": param4,
                "param5": param5,
                "param6": param6,
                "param7": param7,
                "param8": param8,
                "param9": param9,
            }
        )

        return all_results

    def objective(trial):
        # é‡‡æ ·å‚æ•°
        p1 = trial.suggest_int("TL_Etag_T2_UE_MAX", param1_start, param1_end)
        # ä¿è¯ p2 > p1
        p2_low = p1 + 1
        if p2_low > param2_end:
            raise TrialPruned()
        p2 = trial.suggest_int("TL_Etag_T1_UE_MAX", p2_low, param2_end)
        p3 = trial.suggest_int("TR_Etag_T2_UE_MAX", param3_start, param3_end)
        # ä¿è¯ p4 > max(p2, p3)
        p4_low = max(p2, p3) + 1
        if p4_low > param4_end:
            raise TrialPruned()
        p4 = trial.suggest_int("RB_IN_FIFO_DEPTH", p4_low, param4_end)

        # æ–°å¢å‚æ•°
        p5 = trial.suggest_int("TU_Etag_T2_UE_MAX", param5_start, param5_end)
        # ä¿è¯ p6 > p5
        p6_low = p5 + 1
        if p6_low > param6_end:
            raise TrialPruned()
        p6 = trial.suggest_int("TU_Etag_T1_UE_MAX", p6_low, param6_end)
        p7 = trial.suggest_int("TD_Etag_T2_UE_MAX", param7_start, param7_end)
        # ä¿è¯ p8 > max(p6, p7)
        p8_low = max(p6, p7) + 1
        if p8_low > param8_end:
            raise TrialPruned()
        p8 = trial.suggest_int("EQ_IN_FIFO_DEPTH", p8_low, param8_end)
        p9 = trial.suggest_int("ETag_BOTHSIDE_UPGRADE", param9_start, param9_end)

        results = _run_one(p1, p2, p3, p4, p5, p6, p7, p8, p9)

        # â”€â”€â”€ ä¸¤ä¸ª traffic çš„å¸¦å®½å‡å€¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        weighted_bw = results["Total_sum_BW_weighted_mean"]

        # â”€â”€â”€ å‚æ•°è§„æ¨¡å½’ä¸€åŒ–ï¼ˆè¶Šå°è¶Šå¥½ï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        param_penalty = (
            # (p1 - param1_start) / (param1_end - param1_start)
            # + (p2 - param2_start) / (param2_end - param2_start)
            # + (p3 - param3_start) / (param3_end - param3_start)
            +(p4 - param4_start) / (param4_end - param4_start)
            # + (p5 - param5_start) / (param5_end - param5_start)
            # + (p6 - param6_start) / (param6_end - param6_start)
            + (p8 - param8_start) / (param8_end - param8_start)
        ) / 2.0

        # ç»¼åˆæŒ‡æ ‡ = åŠ æƒå¸¦å®½ - Î± * å‚æ•°æƒ©ç½š
        # è°ƒæ•´Î±å€¼å¹³è¡¡æ€§èƒ½å’Œèµ„æºæ¶ˆè€—
        # composite_metric = weighted_bw - 50 * param_penalty
        # Î± æ ¹æ®è¯•éªŒè¿›åº¦è‡ªé€‚åº”ï¼Œå‰æœŸçº¦æŸæ›´å¼ºï¼ŒåæœŸé€æ¸å‡å¼±
        progress = min(trial.number / N_TRIALS, 1.0)
        penalty_weight = 50 * (1 - progress)
        composite_metric = weighted_bw - penalty_weight * param_penalty

        # ä¿å­˜åˆ° trial.user_attrsï¼Œä¾¿äºåæœŸåˆ†æ / CSV
        for k, v in results.items():
            trial.set_user_attr(k, v)
        trial.set_user_attr("param_penalty", param_penalty)
        trial.set_user_attr("penalty_weight", penalty_weight)
        trial.set_user_attr("composite_metric", composite_metric)

        # â”€â”€â”€ å¤šç›®æ ‡è¿”å›ï¼š (maximize, maximize, minimize) â”€â”€â”€â”€
        return composite_metric

    return objective, output_csv, traffic_files, traffic_weights, result_root_save_path


def save_intermediate_result(study, trial):
    """ä¿å­˜å·²å®Œæˆ (COMPLETE) çš„ trial åˆ° CSVï¼Œå¹¶åˆ›å»ºå®æ—¶å¯è§†åŒ–"""
    records = []
    for t in study.trials:
        if t.state != TrialState.COMPLETE:
            continue
        rec = {
            "number": t.number,
            "values": t.values,
            "state": t.state.name,
        }
        rec.update(t.params)
        rec.update(t.user_attrs)
        records.append(rec)

    # ä¿å­˜CSV
    pd.DataFrame(records).to_csv(output_csv, index=False, encoding='utf-8-sig')

    # ä¿å­˜è¿›åº¦å¹¶åˆ›å»ºå®æ—¶å¯è§†åŒ–
    save_progress_callback(study, trial)


def create_summary_report(study, traffic_files, traffic_weights, save_dir):
    """åˆ›å»ºHTMLæ€»ç»“æŠ¥å‘Š"""
    complete_trials = [t for t in study.trials if t.state == TrialState.COMPLETE]

    if not complete_trials:
        return

    # è·å–æœ€ä½³è¯•éªŒ
    best_trial = study.best_trials[0]
    # è·å–Top 10è¯•éªŒ
    top_trials = sorted(complete_trials, key=lambda t: t.values[0] if t.values else -np.inf, reverse=True)[:10]

    # ç”ŸæˆHTMLæŠ¥å‘Š
    html_content = f"""
    <!DOCTYPE html>
    <html>
    <head>
        <title>å¤šTrafficå‚æ•°ä¼˜åŒ–æŠ¥å‘Š</title>
        <meta charset="utf-8">
        <style>
            body {{ font-family: Arial, sans-serif; margin: 40px; }}
            .header {{ background-color: #f4f4f4; padding: 20px; border-radius: 5px; }}
            .section {{ margin: 20px 0; }}
            .best-params {{ background-color: #e8f5e8; padding: 15px; border-radius: 5px; }}
            .table {{ border-collapse: collapse; width: 100%; }}
            .table th, .table td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
            .table th {{ background-color: #f2f2f2; }}
            .metric {{ display: inline-block; margin: 10px; padding: 10px; background-color: #f9f9f9; border-radius: 3px; }}
        </style>
    </head>
    <body>
        <div class="header">
            <h1>å¤šTrafficå‚æ•°ä¼˜åŒ–æŠ¥å‘Š</h1>
            <p>ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
            <p>å®Œæˆè¯•éªŒæ•°: {len(complete_trials)} / {len(study.trials)}</p>
        </div>
        
        <div class="section">
            <h2>ä¼˜åŒ–é…ç½®</h2>
            <div class="metric">
                <strong>Trafficæ–‡ä»¶:</strong><br>
                {', '.join(traffic_files)}
            </div>
            <div class="metric">
                <strong>æƒé‡é…ç½®:</strong><br>
                {', '.join([f'{tf[:-4]}: {w:.1%}' for tf, w in zip(traffic_files, traffic_weights)])}
            </div>
        </div>
        
        <div class="section best-params">
            <h2>æœ€ä½³é…ç½®</h2>
            <p><strong>æœ€ä½³æŒ‡æ ‡(BW1, BW2, Norm):</strong> {best_trial.values}</p>
            <p><strong>æœ€ä½³å‚æ•°:</strong></p>
            <ul>
    """

    for param, value in best_trial.params.items():
        html_content += f"<li>{param}: {int(value)}</li>"

    html_content += f"""
            </ul>
            <p><strong>æ€§èƒ½è¯¦æƒ…:</strong></p>
            <ul>
    """

    for traffic_file in traffic_files:
        traffic_name = traffic_file[:-4]
        if f"Total_sum_BW_mean_{traffic_name}" in best_trial.user_attrs:
            bw = best_trial.user_attrs[f"Total_sum_BW_mean_{traffic_name}"]
            html_content += f"<li>{traffic_name}: {bw:.2f} GB/s</li>"

    weighted_bw = best_trial.user_attrs.get("Total_sum_BW_weighted_mean", 0)
    min_bw = best_trial.user_attrs.get("Total_sum_BW_min", 0)
    variance = best_trial.user_attrs.get("Total_sum_BW_variance", 0)

    html_content += f"""
                <li>åŠ æƒå¹³å‡: {weighted_bw:.2f} GB/s</li>
                <li>æœ€å°å€¼: {min_bw:.2f} GB/s</li>
                <li>æ–¹å·®: {variance:.2f}</li>
            </ul>
        </div>
        
        <div class="section">
            <h2>Top 10 é…ç½®</h2>
            <table class="table">
                <tr>
                    <th>æ’å</th>
                    <th>Trial</th>
                    <th>æŒ‡æ ‡(BW1, BW2, Norm)</th>
                    <th>åŠ æƒå¹³å‡</th>
                    <th>æœ€å°å€¼</th>
                    <th>æ–¹å·®</th>
    """

    for param in best_trial.params.keys():
        html_content += f"<th>{param}</th>"

    html_content += "</tr>"

    for i, trial in enumerate(top_trials, 1):
        weighted = trial.user_attrs.get("Total_sum_BW_weighted_mean", 0)
        min_val = trial.user_attrs.get("Total_sum_BW_min", 0)
        var_val = trial.user_attrs.get("Total_sum_BW_variance", 0)

        html_content += f"""
                <tr>
                    <td>{i}</td>
                    <td>{trial.number}</td>
                    <td>{trial.values}</td>
                    <td>{weighted:.2f}</td>
                    <td>{min_val:.2f}</td>
                    <td>{var_val:.2f}</td>
        """

        for param in best_trial.params.keys():
            html_content += f"<td>{trial.params.get(param, '-')}</td>"

        html_content += "</tr>"

    html_content += f"""
            </table>
        </div>
        
        <div class="section">
            <h2>å¯è§†åŒ–å›¾è¡¨</h2>
            <p>è¯¦ç»†çš„å¯è§†åŒ–åˆ†æè¯·æŸ¥çœ‹ä»¥ä¸‹æ–‡ä»¶:</p>
            <ul>
                <li><a href="visualizations/optimization_history.html">ä¼˜åŒ–å†å²</a></li>
                <li><a href="visualizations/parameter_importance.html">å‚æ•°é‡è¦æ€§</a></li>
                <li><a href="visualizations/pareto_front.html">Paretoå‰æ²¿</a></li>
                <li><a href="visualizations/multi_traffic_comparison.html">å¤šTrafficå¯¹æ¯”</a></li>
                <li><a href="visualizations/convergence_analysis.html">æ”¶æ•›åˆ†æ</a></li>
                <li><a href="visualizations/3d_parameter_space.html">3Då‚æ•°ç©ºé—´</a></li>
            </ul>
        </div>
    </body>
    </html>
    """

    # ä¿å­˜HTMLæŠ¥å‘Š
    with open(os.path.join(save_dir, "optimization_report.html"), "w", encoding="utf-8") as f:
        f.write(html_content)

    print(f"æ€»ç»“æŠ¥å‘Šå·²ç”Ÿæˆ: {save_dir}/optimization_report.html")


if __name__ == "__main__":
    objective, output_csv, traffic_files, traffic_weights, result_root_save_path = find_optimal_parameters()

    print("=" * 60)
    print(f"å¼€å§‹å¤šTrafficä¼˜åŒ– - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"Trafficæ–‡ä»¶: {traffic_files}")
    print(f"æƒé‡: {traffic_weights}")
    print(f"ç»“æœä¿å­˜è·¯å¾„: {result_root_save_path}")
    print("=" * 60)

    n_trials = N_TRIALS

    study = optuna.create_study(
        study_name="CrossRing_Single_Traffic_BO",
        direction="maximize",
        sampler=optuna.samplers.NSGAIISampler(),
    )

    try:
        study.optimize(
            objective,
            n_trials=n_trials,
            n_jobs=N_JOBS,
            show_progress_bar=True,
            callbacks=[save_intermediate_result],
        )
    except KeyboardInterrupt:
        print("ä¼˜åŒ–è¢«ç”¨æˆ·ä¸­æ–­")

    # ä¿å­˜æœ€ç»ˆç»“æœ
    final_records = []
    for t in study.trials:
        if t.state != TrialState.COMPLETE:
            continue
        rec = {
            "number": t.number,
            "value": t.values,
            "state": t.state.name,
        }
        rec.update(t.params)
        rec.update(t.user_attrs)
        final_records.append(rec)

    final_df = pd.DataFrame(final_records)
    final_df.to_csv(output_csv, index=False, encoding='utf-8-sig')

    print("\n" + "=" * 60)
    print("ä¼˜åŒ–å®Œæˆ!")
    if study.best_trials:
        print("æœ€ä½³æŒ‡æ ‡(BW1, BW2, Norm):", study.best_trials[0].values)
        print("æœ€ä½³å‚æ•°:", study.best_trials[0].params)

    # æ˜¾ç¤ºæœ€ä½³ç»“æœçš„è¯¦ç»†ä¿¡æ¯
    if study.best_trials:
        best_trial = study.best_trials[0]
        print("\næœ€ä½³é…ç½®çš„è¯¦ç»†ç»“æœ:")
        for traffic_file in traffic_files:
            traffic_name = traffic_file[:-4]
            if f"Total_sum_BW_mean_{traffic_name}" in best_trial.user_attrs:
                print(f"  {traffic_name}: {best_trial.user_attrs[f'Total_sum_BW_mean_{traffic_name}']:.2f} GB/s")
        print(f"  åŠ æƒå¹³å‡: {best_trial.user_attrs.get('Total_sum_BW_weighted_mean', 0):.2f} GB/s")
        print(f"  æœ€å°å€¼: {best_trial.user_attrs.get('Total_sum_BW_min', 0):.2f} GB/s")
        print(f"  æ–¹å·®: {best_trial.user_attrs.get('Total_sum_BW_variance', 0):.2f}")

    # åˆ›å»ºæœ€ç»ˆå¯è§†åŒ–
    print("\næ­£åœ¨ç”Ÿæˆæœ€ç»ˆå¯è§†åŒ–æŠ¥å‘Š...")
    try:
        enhanced_create_visualization_plots(study, traffic_files, traffic_weights, result_root_save_path)
        print(f"å¯è§†åŒ–æŠ¥å‘Šå·²ç”Ÿæˆ: {result_root_save_path}/visualizations/")

        # åˆ›å»ºæ€»ç»“æŠ¥å‘Š
        create_summary_report(study, traffic_files, traffic_weights, result_root_save_path)

    except Exception as e:
        print(f"ç”Ÿæˆå¯è§†åŒ–å¤±è´¥: {e}")
        traceback.print_exc()

    print("=" * 60)

    # 1. ä¿å­˜Studyå¯¹è±¡
    study_file = os.path.join(result_root_save_path, "optuna_study.pkl")
    import joblib

    joblib.dump(study, study_file)
    print(f"Studyå¯¹è±¡å·²ä¿å­˜: {study_file}")

    # 2. ä¿å­˜ä¼˜åŒ–é…ç½®
    config_data = {
        "traffic_files": traffic_files,
        "traffic_weights": traffic_weights,
        "param_ranges": {
            "TL_Etag_T2_UE_MAX": [2, 16],
            "TL_Etag_T1_UE_MAX": [2, 16],
            "TR_Etag_T2_UE_MAX": [2, 16],
            "RB_IN_FIFO_DEPTH": [4, 20],
            "TU_Etag_T2_UE_MAX": [2, 16],
            "TU_Etag_T1_UE_MAX": [2, 16],
            "TD_Etag_T2_UE_MAX": [2, 16],
            "EQ_IN_FIFO_DEPTH": [4, 20],
            "ETag_BOTHSIDE_UPGRADE": [0, 1],
        },
        "n_trials": n_trials,
        "n_repeats": N_REPEATS,
        "timestamp": datetime.now().isoformat(),
        "result_root_save_path": result_root_save_path,
    }

    config_file = os.path.join(result_root_save_path, "optimization_config.json")
    with open(config_file, "w", encoding="utf-8") as f:
        json.dump(config_data, f, indent=2, ensure_ascii=False)
    print(f"ä¼˜åŒ–é…ç½®å·²ä¿å­˜: {config_file}")

    print("\nğŸ“ å·²ä¿å­˜ä»¥ä¸‹æ–‡ä»¶ç”¨äºåç»­åˆ†æ:")
    print(f"  â€¢ Studyå¯¹è±¡: {study_file}")
    print(f"  â€¢ é…ç½®æ–‡ä»¶: {config_file}")
    print(f"  â€¢ CSVæ•°æ®: {output_csv}")
    print(f"  â€¢ HTMLæŠ¥å‘Š: {result_root_save_path}/optimization_report.html")
    print(f"  â€¢ å¯è§†åŒ–: {result_root_save_path}/visualizations/")

    print(f"\nğŸ”„ é‡æ–°ç”Ÿæˆåˆ†æè¯·è¿è¡Œ:")
    print(f"python regenerate_analysis.py ../{result_root_save_path}")
